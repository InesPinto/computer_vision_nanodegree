{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** I didn't change the CNN architecture (encoder) because it was already provided, in the decoder I started with an embedding layer (embedded Image vector), then the LSTM layer and ended with a fully-connected output layer with the output of the LSTM layer. The Minibatch Size as recommended by the lectures should be between 32 and 128/256 so 64 seamed a good value to start, hidden_size and embed_size were set to 512 as seen in the papers provided, the vocab_threshold was set to 3 to increase the vocabulary available and I kept the num_epochs to see results more easily.\n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** After some research, I found that Adam is relatively easy to configure where the default configuration parameters do well on most problems with is good in my case as I'm still entering this field, uses is to adaptively select a separate learning rate for each parameter and because learning rates are adjusted automatically, manual tuning becomes less important. Adam is also a popular algorithm in the field of deep learning because it achieves good results fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 343/414113 [00:00<02:00, 3429.45it/s]\u001b[A\n",
      "  0%|          | 772/414113 [00:00<01:53, 3647.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=1.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  0%|          | 1200/414113 [00:00<01:48, 3816.13it/s]\u001b[A\n",
      "  0%|          | 1623/414113 [00:00<01:44, 3929.85it/s]\u001b[A\n",
      "  0%|          | 2033/414113 [00:00<01:43, 3979.30it/s]\u001b[A\n",
      "  1%|          | 2462/414113 [00:00<01:41, 4067.17it/s]\u001b[A\n",
      "  1%|          | 2888/414113 [00:00<01:39, 4122.21it/s]\u001b[A\n",
      "  1%|          | 3314/414113 [00:00<01:38, 4160.40it/s]\u001b[A\n",
      "  1%|          | 3749/414113 [00:00<01:37, 4215.00it/s]\u001b[A\n",
      "  1%|          | 4188/414113 [00:01<01:36, 4263.84it/s]\u001b[A\n",
      "  1%|          | 4620/414113 [00:01<01:35, 4277.88it/s]\u001b[A\n",
      "  1%|          | 5070/414113 [00:01<01:34, 4339.79it/s]\u001b[A\n",
      "  1%|▏         | 5500/414113 [00:01<01:34, 4324.89it/s]\u001b[A\n",
      "  1%|▏         | 5930/414113 [00:01<01:34, 4306.41it/s]\u001b[A\n",
      "  2%|▏         | 6359/414113 [00:01<01:38, 4138.42it/s]\u001b[A\n",
      "  2%|▏         | 6786/414113 [00:01<01:37, 4176.54it/s]\u001b[A\n",
      "  2%|▏         | 7223/414113 [00:01<01:36, 4230.84it/s]\u001b[A\n",
      "  2%|▏         | 7650/414113 [00:01<01:35, 4241.53it/s]\u001b[A\n",
      "  2%|▏         | 8090/414113 [00:01<01:34, 4285.15it/s]\u001b[A\n",
      "  2%|▏         | 8531/414113 [00:02<01:33, 4320.91it/s]\u001b[A\n",
      "  2%|▏         | 8965/414113 [00:02<01:33, 4325.82it/s]\u001b[A\n",
      "  2%|▏         | 9398/414113 [00:02<01:35, 4255.84it/s]\u001b[A\n",
      "  2%|▏         | 9824/414113 [00:02<01:35, 4230.37it/s]\u001b[A\n",
      "  2%|▏         | 10248/414113 [00:02<01:37, 4161.37it/s]\u001b[A\n",
      "  3%|▎         | 10667/414113 [00:02<01:36, 4169.90it/s]\u001b[A\n",
      "  3%|▎         | 11085/414113 [00:02<01:37, 4140.55it/s]\u001b[A\n",
      "  3%|▎         | 11511/414113 [00:02<01:36, 4175.56it/s]\u001b[A\n",
      "  3%|▎         | 11943/414113 [00:02<01:35, 4217.17it/s]\u001b[A\n",
      "  3%|▎         | 12366/414113 [00:02<01:35, 4211.61it/s]\u001b[A\n",
      "  3%|▎         | 12801/414113 [00:03<01:34, 4249.61it/s]\u001b[A\n",
      "  3%|▎         | 13240/414113 [00:03<01:33, 4289.53it/s]\u001b[A\n",
      "  3%|▎         | 13688/414113 [00:03<01:32, 4344.87it/s]\u001b[A\n",
      "  3%|▎         | 14123/414113 [00:03<01:32, 4336.53it/s]\u001b[A\n",
      "  4%|▎         | 14557/414113 [00:03<01:33, 4273.50it/s]\u001b[A\n",
      "  4%|▎         | 14991/414113 [00:03<01:32, 4292.53it/s]\u001b[A\n",
      "  4%|▎         | 15433/414113 [00:03<01:32, 4329.38it/s]\u001b[A\n",
      "  4%|▍         | 15868/414113 [00:03<01:31, 4334.51it/s]\u001b[A\n",
      "  4%|▍         | 16302/414113 [00:03<01:31, 4326.56it/s]\u001b[A\n",
      "  4%|▍         | 16744/414113 [00:03<01:31, 4351.84it/s]\u001b[A\n",
      "  4%|▍         | 17185/414113 [00:04<01:30, 4368.27it/s]\u001b[A\n",
      "  4%|▍         | 17628/414113 [00:04<01:30, 4386.50it/s]\u001b[A\n",
      "  4%|▍         | 18073/414113 [00:04<01:29, 4405.21it/s]\u001b[A\n",
      "  4%|▍         | 18514/414113 [00:04<01:30, 4383.16it/s]\u001b[A\n",
      "  5%|▍         | 18953/414113 [00:04<01:31, 4338.80it/s]\u001b[A\n",
      "  5%|▍         | 19393/414113 [00:04<01:30, 4354.06it/s]\u001b[A\n",
      "  5%|▍         | 19835/414113 [00:04<01:30, 4373.29it/s]\u001b[A\n",
      "  5%|▍         | 20273/414113 [00:04<01:33, 4220.81it/s]\u001b[A\n",
      "  5%|▍         | 20697/414113 [00:04<01:35, 4130.75it/s]\u001b[A\n",
      "  5%|▌         | 21112/414113 [00:04<01:36, 4092.53it/s]\u001b[A\n",
      "  5%|▌         | 21523/414113 [00:05<01:36, 4058.24it/s]\u001b[A\n",
      "  5%|▌         | 21930/414113 [00:05<01:37, 4015.19it/s]\u001b[A\n",
      "  5%|▌         | 22342/414113 [00:05<01:36, 4043.83it/s]\u001b[A\n",
      "  5%|▌         | 22747/414113 [00:05<01:40, 3899.46it/s]\u001b[A\n",
      "  6%|▌         | 23175/414113 [00:05<01:37, 4004.49it/s]\u001b[A\n",
      "  6%|▌         | 23603/414113 [00:05<01:35, 4080.78it/s]\u001b[A\n",
      "  6%|▌         | 24039/414113 [00:05<01:33, 4160.70it/s]\u001b[A\n",
      "  6%|▌         | 24472/414113 [00:05<01:32, 4209.05it/s]\u001b[A\n",
      "  6%|▌         | 24897/414113 [00:05<01:32, 4219.89it/s]\u001b[A\n",
      "  6%|▌         | 25333/414113 [00:05<01:31, 4260.43it/s]\u001b[A\n",
      "  6%|▌         | 25779/414113 [00:06<01:29, 4318.02it/s]\u001b[A\n",
      "  6%|▋         | 26212/414113 [00:06<01:29, 4317.75it/s]\u001b[A\n",
      "  6%|▋         | 26646/414113 [00:06<01:29, 4322.85it/s]\u001b[A\n",
      "  7%|▋         | 27079/414113 [00:06<01:30, 4296.75it/s]\u001b[A\n",
      "  7%|▋         | 27515/414113 [00:06<01:29, 4312.00it/s]\u001b[A\n",
      "  7%|▋         | 27956/414113 [00:06<01:29, 4338.00it/s]\u001b[A\n",
      "  7%|▋         | 28390/414113 [00:06<01:29, 4324.10it/s]\u001b[A\n",
      "  7%|▋         | 28823/414113 [00:06<01:29, 4319.53it/s]\u001b[A\n",
      "  7%|▋         | 29263/414113 [00:06<01:28, 4340.93it/s]\u001b[A\n",
      "  7%|▋         | 29698/414113 [00:06<01:28, 4329.29it/s]\u001b[A\n",
      "  7%|▋         | 30155/414113 [00:07<01:27, 4398.18it/s]\u001b[A\n",
      "  7%|▋         | 30596/414113 [00:07<01:27, 4388.58it/s]\u001b[A\n",
      "  7%|▋         | 31036/414113 [00:07<01:27, 4367.67it/s]\u001b[A\n",
      "  8%|▊         | 31482/414113 [00:07<01:27, 4394.66it/s]\u001b[A\n",
      "  8%|▊         | 31925/414113 [00:07<01:26, 4404.75it/s]\u001b[A\n",
      "  8%|▊         | 32366/414113 [00:07<01:26, 4391.53it/s]\u001b[A\n",
      "  8%|▊         | 32806/414113 [00:07<01:27, 4376.16it/s]\u001b[A\n",
      "  8%|▊         | 33244/414113 [00:07<01:27, 4349.90it/s]\u001b[A\n",
      "  8%|▊         | 33685/414113 [00:07<01:27, 4365.15it/s]\u001b[A\n",
      "  8%|▊         | 34130/414113 [00:08<01:26, 4387.39it/s]\u001b[A\n",
      "  8%|▊         | 34569/414113 [00:08<01:27, 4345.41it/s]\u001b[A\n",
      "  8%|▊         | 35004/414113 [00:08<01:27, 4341.10it/s]\u001b[A\n",
      "  9%|▊         | 35439/414113 [00:08<01:27, 4312.70it/s]\u001b[A\n",
      "  9%|▊         | 35871/414113 [00:08<01:28, 4252.83it/s]\u001b[A\n",
      "  9%|▉         | 36297/414113 [00:08<01:29, 4223.42it/s]\u001b[A\n",
      "  9%|▉         | 36732/414113 [00:08<01:28, 4258.42it/s]\u001b[A\n",
      "  9%|▉         | 37170/414113 [00:08<01:27, 4292.43it/s]\u001b[A\n",
      "  9%|▉         | 37616/414113 [00:08<01:26, 4341.03it/s]\u001b[A\n",
      "  9%|▉         | 38059/414113 [00:08<01:26, 4364.92it/s]\u001b[A\n",
      "  9%|▉         | 38496/414113 [00:09<01:26, 4360.81it/s]\u001b[A\n",
      "  9%|▉         | 38941/414113 [00:09<01:25, 4385.36it/s]\u001b[A\n",
      " 10%|▉         | 39380/414113 [00:09<01:26, 4334.16it/s]\u001b[A\n",
      " 10%|▉         | 39826/414113 [00:09<01:25, 4371.11it/s]\u001b[A\n",
      " 10%|▉         | 40264/414113 [00:09<01:25, 4363.47it/s]\u001b[A\n",
      " 10%|▉         | 40701/414113 [00:09<01:26, 4312.46it/s]\u001b[A\n",
      " 10%|▉         | 41133/414113 [00:09<01:29, 4149.50it/s]\u001b[A\n",
      " 10%|█         | 41575/414113 [00:09<01:28, 4226.68it/s]\u001b[A\n",
      " 10%|█         | 42008/414113 [00:09<01:27, 4254.52it/s]\u001b[A\n",
      " 10%|█         | 42444/414113 [00:09<01:26, 4284.36it/s]\u001b[A\n",
      " 10%|█         | 42877/414113 [00:10<01:26, 4296.69it/s]\u001b[A\n",
      " 10%|█         | 43308/414113 [00:10<01:26, 4290.43it/s]\u001b[A\n",
      " 11%|█         | 43743/414113 [00:10<01:25, 4307.52it/s]\u001b[A\n",
      " 11%|█         | 44176/414113 [00:10<01:25, 4313.00it/s]\u001b[A\n",
      " 11%|█         | 44608/414113 [00:10<01:26, 4252.49it/s]\u001b[A\n",
      " 11%|█         | 45049/414113 [00:10<01:25, 4295.80it/s]\u001b[A\n",
      " 11%|█         | 45479/414113 [00:10<01:25, 4295.60it/s]\u001b[A\n",
      " 11%|█         | 45918/414113 [00:10<01:25, 4320.37it/s]\u001b[A\n",
      " 11%|█         | 46361/414113 [00:10<01:24, 4350.22it/s]\u001b[A\n",
      " 11%|█▏        | 46797/414113 [00:10<01:24, 4353.04it/s]\u001b[A\n",
      " 11%|█▏        | 47234/414113 [00:11<01:24, 4355.39it/s]\u001b[A\n",
      " 12%|█▏        | 47670/414113 [00:11<01:24, 4347.84it/s]\u001b[A\n",
      " 12%|█▏        | 48109/414113 [00:11<01:23, 4357.85it/s]\u001b[A\n",
      " 12%|█▏        | 48545/414113 [00:11<01:23, 4357.04it/s]\u001b[A\n",
      " 12%|█▏        | 48981/414113 [00:11<01:24, 4298.16it/s]\u001b[A\n",
      " 12%|█▏        | 49412/414113 [00:11<01:25, 4281.15it/s]\u001b[A\n",
      " 12%|█▏        | 49857/414113 [00:11<01:24, 4329.13it/s]\u001b[A\n",
      " 12%|█▏        | 50297/414113 [00:11<01:23, 4349.58it/s]\u001b[A\n",
      " 12%|█▏        | 50736/414113 [00:11<01:23, 4360.90it/s]\u001b[A\n",
      " 12%|█▏        | 51177/414113 [00:11<01:22, 4372.99it/s]\u001b[A\n",
      " 12%|█▏        | 51618/414113 [00:12<01:22, 4383.62it/s]\u001b[A\n",
      " 13%|█▎        | 52057/414113 [00:12<01:22, 4373.84it/s]\u001b[A\n",
      " 13%|█▎        | 52495/414113 [00:12<01:22, 4369.59it/s]\u001b[A\n",
      " 13%|█▎        | 52933/414113 [00:12<01:22, 4360.91it/s]\u001b[A\n",
      " 13%|█▎        | 53370/414113 [00:12<01:23, 4318.24it/s]\u001b[A\n",
      " 13%|█▎        | 53807/414113 [00:12<01:23, 4332.59it/s]\u001b[A\n",
      " 13%|█▎        | 54249/414113 [00:12<01:22, 4355.68it/s]\u001b[A\n",
      " 13%|█▎        | 54685/414113 [00:12<01:24, 4234.24it/s]\u001b[A\n",
      " 13%|█▎        | 55131/414113 [00:12<01:23, 4298.27it/s]\u001b[A\n",
      " 13%|█▎        | 55573/414113 [00:12<01:22, 4332.99it/s]\u001b[A\n",
      " 14%|█▎        | 56011/414113 [00:13<01:22, 4346.07it/s]\u001b[A\n",
      " 14%|█▎        | 56450/414113 [00:13<01:22, 4358.18it/s]\u001b[A\n",
      " 14%|█▎        | 56894/414113 [00:13<01:21, 4380.44it/s]\u001b[A\n",
      " 14%|█▍        | 57333/414113 [00:13<01:22, 4340.33it/s]\u001b[A\n",
      " 14%|█▍        | 57768/414113 [00:13<01:22, 4305.32it/s]\u001b[A\n",
      " 14%|█▍        | 58203/414113 [00:13<01:22, 4318.34it/s]\u001b[A\n",
      " 14%|█▍        | 58636/414113 [00:13<01:22, 4297.55it/s]\u001b[A\n",
      " 14%|█▍        | 59082/414113 [00:13<01:21, 4343.98it/s]\u001b[A\n",
      " 14%|█▍        | 59517/414113 [00:13<01:21, 4332.61it/s]\u001b[A\n",
      " 14%|█▍        | 59954/414113 [00:13<01:21, 4342.17it/s]\u001b[A\n",
      " 15%|█▍        | 60401/414113 [00:14<01:20, 4378.89it/s]\u001b[A\n",
      " 15%|█▍        | 60840/414113 [00:14<01:21, 4358.38it/s]\u001b[A\n",
      " 15%|█▍        | 61286/414113 [00:14<01:20, 4386.32it/s]\u001b[A\n",
      " 15%|█▍        | 61725/414113 [00:14<01:21, 4336.61it/s]\u001b[A\n",
      " 15%|█▌        | 62159/414113 [00:14<01:21, 4304.55it/s]\u001b[A\n",
      " 15%|█▌        | 62590/414113 [00:14<01:21, 4303.85it/s]\u001b[A\n",
      " 15%|█▌        | 63021/414113 [00:14<01:22, 4274.70it/s]\u001b[A\n",
      " 15%|█▌        | 63459/414113 [00:14<01:21, 4303.94it/s]\u001b[A\n",
      " 15%|█▌        | 63901/414113 [00:14<01:20, 4337.35it/s]\u001b[A\n",
      " 16%|█▌        | 64335/414113 [00:14<01:20, 4327.55it/s]\u001b[A\n",
      " 16%|█▌        | 64768/414113 [00:15<01:20, 4323.98it/s]\u001b[A\n",
      " 16%|█▌        | 65213/414113 [00:15<01:20, 4357.92it/s]\u001b[A\n",
      " 16%|█▌        | 65649/414113 [00:15<01:20, 4314.86it/s]\u001b[A\n",
      " 16%|█▌        | 66095/414113 [00:15<01:19, 4355.40it/s]\u001b[A\n",
      " 16%|█▌        | 66531/414113 [00:15<01:20, 4306.76it/s]\u001b[A\n",
      " 16%|█▌        | 66975/414113 [00:15<01:19, 4343.34it/s]\u001b[A\n",
      " 16%|█▋        | 67411/414113 [00:15<01:19, 4348.20it/s]\u001b[A\n",
      " 16%|█▋        | 67847/414113 [00:15<01:19, 4346.27it/s]\u001b[A\n",
      " 16%|█▋        | 68293/414113 [00:15<01:19, 4377.39it/s]\u001b[A\n",
      " 17%|█▋        | 68731/414113 [00:16<01:20, 4306.13it/s]\u001b[A\n",
      " 17%|█▋        | 69175/414113 [00:16<01:19, 4343.95it/s]\u001b[A\n",
      " 17%|█▋        | 69612/414113 [00:16<01:19, 4350.57it/s]\u001b[A\n",
      " 17%|█▋        | 70069/414113 [00:16<01:17, 4412.64it/s]\u001b[A\n",
      " 17%|█▋        | 70511/414113 [00:16<01:18, 4394.09it/s]\u001b[A\n",
      " 17%|█▋        | 70951/414113 [00:16<01:18, 4383.37it/s]\u001b[A\n",
      " 17%|█▋        | 71390/414113 [00:16<01:18, 4382.36it/s]\u001b[A\n",
      " 17%|█▋        | 71829/414113 [00:16<01:18, 4366.08it/s]\u001b[A\n",
      " 17%|█▋        | 72273/414113 [00:16<01:17, 4387.34it/s]\u001b[A\n",
      " 18%|█▊        | 72712/414113 [00:16<01:18, 4330.37it/s]\u001b[A\n",
      " 18%|█▊        | 73154/414113 [00:17<01:18, 4355.55it/s]\u001b[A\n",
      " 18%|█▊        | 73590/414113 [00:17<02:03, 2756.51it/s]\u001b[A\n",
      " 18%|█▊        | 74029/414113 [00:17<01:49, 3101.58it/s]\u001b[A\n",
      " 18%|█▊        | 74446/414113 [00:17<01:41, 3359.47it/s]\u001b[A\n",
      " 18%|█▊        | 74873/414113 [00:17<01:34, 3588.80it/s]\u001b[A\n",
      " 18%|█▊        | 75309/414113 [00:17<01:29, 3788.39it/s]\u001b[A\n",
      " 18%|█▊        | 75743/414113 [00:17<01:25, 3937.34it/s]\u001b[A\n",
      " 18%|█▊        | 76180/414113 [00:17<01:23, 4056.29it/s]\u001b[A\n",
      " 18%|█▊        | 76609/414113 [00:18<01:21, 4122.59it/s]\u001b[A\n",
      " 19%|█▊        | 77039/414113 [00:18<01:20, 4172.87it/s]\u001b[A\n",
      " 19%|█▊        | 77484/414113 [00:18<01:19, 4250.54it/s]\u001b[A\n",
      " 19%|█▉        | 77921/414113 [00:18<01:18, 4285.35it/s]\u001b[A\n",
      " 19%|█▉        | 78355/414113 [00:18<01:18, 4267.58it/s]\u001b[A\n",
      " 19%|█▉        | 78786/414113 [00:18<01:19, 4211.23it/s]\u001b[A\n",
      " 19%|█▉        | 79210/414113 [00:18<01:19, 4199.71it/s]\u001b[A\n",
      " 19%|█▉        | 79658/414113 [00:18<01:18, 4278.46it/s]\u001b[A\n",
      " 19%|█▉        | 80102/414113 [00:18<01:17, 4324.64it/s]\u001b[A\n",
      " 19%|█▉        | 80536/414113 [00:18<01:17, 4293.32it/s]\u001b[A\n",
      " 20%|█▉        | 80981/414113 [00:19<01:16, 4338.43it/s]\u001b[A\n",
      " 20%|█▉        | 81416/414113 [00:19<01:16, 4333.46it/s]\u001b[A\n",
      " 20%|█▉        | 81850/414113 [00:19<01:17, 4314.49it/s]\u001b[A\n",
      " 20%|█▉        | 82297/414113 [00:19<01:16, 4359.13it/s]\u001b[A\n",
      " 20%|█▉        | 82736/414113 [00:19<01:15, 4365.84it/s]\u001b[A\n",
      " 20%|██        | 83173/414113 [00:19<01:15, 4360.71it/s]\u001b[A\n",
      " 20%|██        | 83617/414113 [00:19<01:15, 4382.16it/s]\u001b[A\n",
      " 20%|██        | 84056/414113 [00:19<01:16, 4342.56it/s]\u001b[A\n",
      " 20%|██        | 84494/414113 [00:19<01:15, 4352.61it/s]\u001b[A\n",
      " 21%|██        | 84934/414113 [00:19<01:15, 4365.71it/s]\u001b[A\n",
      " 21%|██        | 85371/414113 [00:20<01:15, 4329.76it/s]\u001b[A\n",
      " 21%|██        | 85805/414113 [00:20<01:15, 4323.12it/s]\u001b[A\n",
      " 21%|██        | 86246/414113 [00:20<01:15, 4348.78it/s]\u001b[A\n",
      " 21%|██        | 86683/414113 [00:20<01:15, 4352.22it/s]\u001b[A\n",
      " 21%|██        | 87119/414113 [00:20<01:15, 4336.77it/s]\u001b[A\n",
      " 21%|██        | 87562/414113 [00:20<01:14, 4363.21it/s]\u001b[A\n",
      " 21%|██▏       | 88014/414113 [00:20<01:13, 4406.89it/s]\u001b[A\n",
      " 21%|██▏       | 88465/414113 [00:20<01:13, 4435.93it/s]\u001b[A\n",
      " 21%|██▏       | 88910/414113 [00:20<01:13, 4439.57it/s]\u001b[A\n",
      " 22%|██▏       | 89355/414113 [00:20<01:13, 4420.19it/s]\u001b[A\n",
      " 22%|██▏       | 89807/414113 [00:21<01:12, 4447.75it/s]\u001b[A\n",
      " 22%|██▏       | 90252/414113 [00:21<01:13, 4412.06it/s]\u001b[A\n",
      " 22%|██▏       | 90699/414113 [00:21<01:13, 4427.02it/s]\u001b[A\n",
      " 22%|██▏       | 91142/414113 [00:21<01:14, 4337.05it/s]\u001b[A\n",
      " 22%|██▏       | 91582/414113 [00:21<01:14, 4353.94it/s]\u001b[A\n",
      " 22%|██▏       | 92018/414113 [00:21<01:14, 4347.89it/s]\u001b[A\n",
      " 22%|██▏       | 92459/414113 [00:21<01:13, 4365.51it/s]\u001b[A\n",
      " 22%|██▏       | 92907/414113 [00:21<01:13, 4396.49it/s]\u001b[A\n",
      " 23%|██▎       | 93348/414113 [00:21<01:12, 4397.95it/s]\u001b[A\n",
      " 23%|██▎       | 93789/414113 [00:21<01:12, 4399.82it/s]\u001b[A\n",
      " 23%|██▎       | 94233/414113 [00:22<01:12, 4411.63it/s]\u001b[A\n",
      " 23%|██▎       | 94681/414113 [00:22<01:12, 4430.77it/s]\u001b[A\n",
      " 23%|██▎       | 95125/414113 [00:22<01:13, 4362.10it/s]\u001b[A\n",
      " 23%|██▎       | 95572/414113 [00:22<01:12, 4391.87it/s]\u001b[A\n",
      " 23%|██▎       | 96012/414113 [00:22<01:13, 4329.77it/s]\u001b[A\n",
      " 23%|██▎       | 96464/414113 [00:22<01:12, 4384.07it/s]\u001b[A\n",
      " 23%|██▎       | 96908/414113 [00:22<01:12, 4399.36it/s]\u001b[A\n",
      " 24%|██▎       | 97356/414113 [00:22<01:11, 4422.78it/s]\u001b[A\n",
      " 24%|██▎       | 97808/414113 [00:22<01:11, 4450.72it/s]\u001b[A\n",
      " 24%|██▎       | 98254/414113 [00:22<01:11, 4408.18it/s]\u001b[A\n",
      " 24%|██▍       | 98700/414113 [00:23<01:11, 4422.29it/s]\u001b[A\n",
      " 24%|██▍       | 99143/414113 [00:23<01:11, 4415.83it/s]\u001b[A\n",
      " 24%|██▍       | 99585/414113 [00:23<01:11, 4396.86it/s]\u001b[A\n",
      " 24%|██▍       | 100025/414113 [00:23<01:11, 4388.35it/s]\u001b[A\n",
      " 24%|██▍       | 100464/414113 [00:23<01:12, 4310.74it/s]\u001b[A\n",
      " 24%|██▍       | 100906/414113 [00:23<01:12, 4341.41it/s]\u001b[A\n",
      " 24%|██▍       | 101341/414113 [00:23<01:12, 4330.73it/s]\u001b[A\n",
      " 25%|██▍       | 101775/414113 [00:23<01:12, 4318.77it/s]\u001b[A\n",
      " 25%|██▍       | 102216/414113 [00:23<01:11, 4344.55it/s]\u001b[A\n",
      " 25%|██▍       | 102665/414113 [00:23<01:11, 4384.42it/s]\u001b[A\n",
      " 25%|██▍       | 103111/414113 [00:24<01:10, 4404.90it/s]\u001b[A\n",
      " 25%|██▌       | 103562/414113 [00:24<01:10, 4432.88it/s]\u001b[A\n",
      " 25%|██▌       | 104006/414113 [00:24<01:10, 4412.72it/s]\u001b[A\n",
      " 25%|██▌       | 104448/414113 [00:24<01:10, 4391.50it/s]\u001b[A\n",
      " 25%|██▌       | 104888/414113 [00:24<01:11, 4330.65it/s]\u001b[A\n",
      " 25%|██▌       | 105328/414113 [00:24<01:10, 4350.42it/s]\u001b[A\n",
      " 26%|██▌       | 105767/414113 [00:24<01:10, 4361.48it/s]\u001b[A\n",
      " 26%|██▌       | 106206/414113 [00:24<01:10, 4367.97it/s]\u001b[A\n",
      " 26%|██▌       | 106643/414113 [00:24<01:10, 4344.46it/s]\u001b[A\n",
      " 26%|██▌       | 107078/414113 [00:24<01:10, 4328.79it/s]\u001b[A\n",
      " 26%|██▌       | 107518/414113 [00:25<01:10, 4348.44it/s]\u001b[A\n",
      " 26%|██▌       | 107953/414113 [00:25<01:10, 4332.62it/s]\u001b[A\n",
      " 26%|██▌       | 108397/414113 [00:25<01:10, 4363.69it/s]\u001b[A\n",
      " 26%|██▋       | 108835/414113 [00:25<01:09, 4368.25it/s]\u001b[A\n",
      " 26%|██▋       | 109275/414113 [00:25<01:09, 4377.51it/s]\u001b[A\n",
      " 26%|██▋       | 109714/414113 [00:25<01:09, 4378.69it/s]\u001b[A\n",
      " 27%|██▋       | 110152/414113 [00:25<01:09, 4359.04it/s]\u001b[A\n",
      " 27%|██▋       | 110588/414113 [00:25<01:14, 4074.59it/s]\u001b[A\n",
      " 27%|██▋       | 111025/414113 [00:25<01:12, 4156.37it/s]\u001b[A\n",
      " 27%|██▋       | 111463/414113 [00:26<01:11, 4218.73it/s]\u001b[A\n",
      " 27%|██▋       | 111902/414113 [00:26<01:10, 4267.99it/s]\u001b[A\n",
      " 27%|██▋       | 112331/414113 [00:26<01:10, 4273.04it/s]\u001b[A\n",
      " 27%|██▋       | 112760/414113 [00:26<01:15, 3999.90it/s]\u001b[A\n",
      " 27%|██▋       | 113201/414113 [00:26<01:13, 4114.17it/s]\u001b[A\n",
      " 27%|██▋       | 113649/414113 [00:26<01:11, 4216.24it/s]\u001b[A\n",
      " 28%|██▊       | 114095/414113 [00:26<01:09, 4286.08it/s]\u001b[A\n",
      " 28%|██▊       | 114539/414113 [00:26<01:09, 4329.47it/s]\u001b[A\n",
      " 28%|██▊       | 114974/414113 [00:26<01:09, 4323.02it/s]\u001b[A\n",
      " 28%|██▊       | 115414/414113 [00:26<01:08, 4345.22it/s]\u001b[A\n",
      " 28%|██▊       | 115867/414113 [00:27<01:07, 4398.76it/s]\u001b[A\n",
      " 28%|██▊       | 116314/414113 [00:27<01:07, 4417.93it/s]\u001b[A\n",
      " 28%|██▊       | 116757/414113 [00:27<01:07, 4406.94it/s]\u001b[A\n",
      " 28%|██▊       | 117199/414113 [00:27<01:07, 4402.41it/s]\u001b[A\n",
      " 28%|██▊       | 117640/414113 [00:27<01:07, 4402.08it/s]\u001b[A\n",
      " 29%|██▊       | 118081/414113 [00:27<01:07, 4402.99it/s]\u001b[A\n",
      " 29%|██▊       | 118522/414113 [00:27<01:07, 4394.46it/s]\u001b[A\n",
      " 29%|██▊       | 118964/414113 [00:27<01:07, 4401.76it/s]\u001b[A\n",
      " 29%|██▉       | 119412/414113 [00:27<01:06, 4424.67it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 119864/414113 [00:27<01:06, 4450.58it/s]\u001b[A\n",
      " 29%|██▉       | 120313/414113 [00:28<01:05, 4460.93it/s]\u001b[A\n",
      " 29%|██▉       | 120767/414113 [00:28<01:05, 4483.25it/s]\u001b[A\n",
      " 29%|██▉       | 121228/414113 [00:28<01:04, 4520.12it/s]\u001b[A\n",
      " 29%|██▉       | 121681/414113 [00:28<01:05, 4461.70it/s]\u001b[A\n",
      " 29%|██▉       | 122128/414113 [00:28<01:05, 4447.31it/s]\u001b[A\n",
      " 30%|██▉       | 122573/414113 [00:28<01:06, 4417.08it/s]\u001b[A\n",
      " 30%|██▉       | 123015/414113 [00:28<01:06, 4395.66it/s]\u001b[A\n",
      " 30%|██▉       | 123455/414113 [00:28<01:06, 4375.55it/s]\u001b[A\n",
      " 30%|██▉       | 123898/414113 [00:28<01:06, 4390.73it/s]\u001b[A\n",
      " 30%|███       | 124344/414113 [00:28<01:05, 4410.29it/s]\u001b[A\n",
      " 30%|███       | 124788/414113 [00:29<01:05, 4417.69it/s]\u001b[A\n",
      " 30%|███       | 125236/414113 [00:29<01:05, 4436.18it/s]\u001b[A\n",
      " 30%|███       | 125687/414113 [00:29<01:04, 4456.08it/s]\u001b[A\n",
      " 30%|███       | 126133/414113 [00:29<01:04, 4454.13it/s]\u001b[A\n",
      " 31%|███       | 126579/414113 [00:29<01:04, 4428.49it/s]\u001b[A\n",
      " 31%|███       | 127022/414113 [00:29<01:04, 4427.75it/s]\u001b[A\n",
      " 31%|███       | 127465/414113 [00:29<01:05, 4399.43it/s]\u001b[A\n",
      " 31%|███       | 127906/414113 [00:29<01:05, 4384.49it/s]\u001b[A\n",
      " 31%|███       | 128351/414113 [00:29<01:04, 4401.44it/s]\u001b[A\n",
      " 31%|███       | 128792/414113 [00:29<01:05, 4369.59it/s]\u001b[A\n",
      " 31%|███       | 129234/414113 [00:30<01:05, 4381.02it/s]\u001b[A\n",
      " 31%|███▏      | 129674/414113 [00:30<01:04, 4385.01it/s]\u001b[A\n",
      " 31%|███▏      | 130123/414113 [00:30<01:04, 4415.33it/s]\u001b[A\n",
      " 32%|███▏      | 130565/414113 [00:30<01:04, 4394.00it/s]\u001b[A\n",
      " 32%|███▏      | 131005/414113 [00:30<01:04, 4372.32it/s]\u001b[A\n",
      " 32%|███▏      | 131450/414113 [00:30<01:04, 4392.91it/s]\u001b[A\n",
      " 32%|███▏      | 131893/414113 [00:30<01:04, 4402.11it/s]\u001b[A\n",
      " 32%|███▏      | 132340/414113 [00:30<01:03, 4421.73it/s]\u001b[A\n",
      " 32%|███▏      | 132783/414113 [00:30<01:03, 4423.33it/s]\u001b[A\n",
      " 32%|███▏      | 133226/414113 [00:30<01:03, 4415.08it/s]\u001b[A\n",
      " 32%|███▏      | 133671/414113 [00:31<01:03, 4424.67it/s]\u001b[A\n",
      " 32%|███▏      | 134114/414113 [00:31<01:03, 4391.13it/s]\u001b[A\n",
      " 32%|███▏      | 134554/414113 [00:31<01:04, 4348.88it/s]\u001b[A\n",
      " 33%|███▎      | 134994/414113 [00:31<01:03, 4361.98it/s]\u001b[A\n",
      " 33%|███▎      | 135431/414113 [00:31<01:04, 4332.63it/s]\u001b[A\n",
      " 33%|███▎      | 135865/414113 [00:31<01:04, 4324.47it/s]\u001b[A\n",
      " 33%|███▎      | 136315/414113 [00:31<01:03, 4374.43it/s]\u001b[A\n",
      " 33%|███▎      | 136753/414113 [00:31<01:03, 4374.79it/s]\u001b[A\n",
      " 33%|███▎      | 137194/414113 [00:31<01:03, 4383.06it/s]\u001b[A\n",
      " 33%|███▎      | 137642/414113 [00:31<01:02, 4410.70it/s]\u001b[A\n",
      " 33%|███▎      | 138085/414113 [00:32<01:02, 4416.27it/s]\u001b[A\n",
      " 33%|███▎      | 138532/414113 [00:32<01:02, 4429.48it/s]\u001b[A\n",
      " 34%|███▎      | 138976/414113 [00:32<01:02, 4422.51it/s]\u001b[A\n",
      " 34%|███▎      | 139428/414113 [00:32<01:01, 4450.78it/s]\u001b[A\n",
      " 34%|███▍      | 139874/414113 [00:32<01:01, 4427.98it/s]\u001b[A\n",
      " 34%|███▍      | 140317/414113 [00:32<01:02, 4387.69it/s]\u001b[A\n",
      " 34%|███▍      | 140756/414113 [00:32<01:02, 4385.27it/s]\u001b[A\n",
      " 34%|███▍      | 141195/414113 [00:32<01:02, 4379.64it/s]\u001b[A\n",
      " 34%|███▍      | 141634/414113 [00:32<01:02, 4381.38it/s]\u001b[A\n",
      " 34%|███▍      | 142075/414113 [00:32<01:01, 4388.94it/s]\u001b[A\n",
      " 34%|███▍      | 142514/414113 [00:33<01:02, 4380.39it/s]\u001b[A\n",
      " 35%|███▍      | 142953/414113 [00:33<01:02, 4356.12it/s]\u001b[A\n",
      " 35%|███▍      | 143396/414113 [00:33<01:01, 4376.46it/s]\u001b[A\n",
      " 35%|███▍      | 143834/414113 [00:33<01:02, 4339.48it/s]\u001b[A\n",
      " 35%|███▍      | 144277/414113 [00:33<01:01, 4365.07it/s]\u001b[A\n",
      " 35%|███▍      | 144714/414113 [00:33<01:03, 4275.07it/s]\u001b[A\n",
      " 35%|███▌      | 145176/414113 [00:33<01:01, 4370.74it/s]\u001b[A\n",
      " 35%|███▌      | 145614/414113 [00:33<01:01, 4372.54it/s]\u001b[A\n",
      " 35%|███▌      | 146060/414113 [00:33<01:00, 4395.02it/s]\u001b[A\n",
      " 35%|███▌      | 146507/414113 [00:34<01:00, 4415.30it/s]\u001b[A\n",
      " 35%|███▌      | 146949/414113 [00:34<01:04, 4162.33it/s]\u001b[A\n",
      " 36%|███▌      | 147393/414113 [00:34<01:02, 4241.45it/s]\u001b[A\n",
      " 36%|███▌      | 147831/414113 [00:34<01:02, 4281.84it/s]\u001b[A\n",
      " 36%|███▌      | 148271/414113 [00:34<01:01, 4313.94it/s]\u001b[A\n",
      " 36%|███▌      | 148710/414113 [00:34<01:01, 4336.43it/s]\u001b[A\n",
      " 36%|███▌      | 149153/414113 [00:34<01:00, 4363.55it/s]\u001b[A\n",
      " 36%|███▌      | 149602/414113 [00:34<01:00, 4399.89it/s]\u001b[A\n",
      " 36%|███▌      | 150049/414113 [00:34<00:59, 4418.71it/s]\u001b[A\n",
      " 36%|███▋      | 150493/414113 [00:34<00:59, 4424.02it/s]\u001b[A\n",
      " 36%|███▋      | 150936/414113 [00:35<00:59, 4423.73it/s]\u001b[A\n",
      " 37%|███▋      | 151387/414113 [00:35<00:59, 4449.02it/s]\u001b[A\n",
      " 37%|███▋      | 151833/414113 [00:35<00:59, 4424.87it/s]\u001b[A\n",
      " 37%|███▋      | 152276/414113 [00:35<00:59, 4402.04it/s]\u001b[A\n",
      " 37%|███▋      | 152722/414113 [00:35<00:59, 4417.27it/s]\u001b[A\n",
      " 37%|███▋      | 153166/414113 [00:35<00:59, 4421.43it/s]\u001b[A\n",
      " 37%|███▋      | 153614/414113 [00:35<00:58, 4436.22it/s]\u001b[A\n",
      " 37%|███▋      | 154069/414113 [00:35<00:58, 4467.61it/s]\u001b[A\n",
      " 37%|███▋      | 154519/414113 [00:35<00:58, 4474.56it/s]\u001b[A\n",
      " 37%|███▋      | 154967/414113 [00:35<00:58, 4451.49it/s]\u001b[A\n",
      " 38%|███▊      | 155413/414113 [00:36<00:58, 4450.00it/s]\u001b[A\n",
      " 38%|███▊      | 155859/414113 [00:36<00:58, 4443.17it/s]\u001b[A\n",
      " 38%|███▊      | 156312/414113 [00:36<00:57, 4465.92it/s]\u001b[A\n",
      " 38%|███▊      | 156761/414113 [00:36<00:57, 4472.82it/s]\u001b[A\n",
      " 38%|███▊      | 157209/414113 [00:36<00:57, 4471.61it/s]\u001b[A\n",
      " 38%|███▊      | 157657/414113 [00:36<00:57, 4444.41it/s]\u001b[A\n",
      " 38%|███▊      | 158107/414113 [00:36<00:57, 4460.38it/s]\u001b[A\n",
      " 38%|███▊      | 158555/414113 [00:36<00:57, 4463.49it/s]\u001b[A\n",
      " 38%|███▊      | 159002/414113 [00:36<00:57, 4464.53it/s]\u001b[A\n",
      " 39%|███▊      | 159449/414113 [00:36<00:57, 4452.88it/s]\u001b[A\n",
      " 39%|███▊      | 159899/414113 [00:37<00:56, 4464.43it/s]\u001b[A\n",
      " 39%|███▊      | 160346/414113 [00:37<00:56, 4461.20it/s]\u001b[A\n",
      " 39%|███▉      | 160796/414113 [00:37<00:56, 4472.36it/s]\u001b[A\n",
      " 39%|███▉      | 161252/414113 [00:37<00:56, 4497.64it/s]\u001b[A\n",
      " 39%|███▉      | 161702/414113 [00:37<00:56, 4471.26it/s]\u001b[A\n",
      " 39%|███▉      | 162150/414113 [00:37<00:56, 4449.27it/s]\u001b[A\n",
      " 39%|███▉      | 162600/414113 [00:37<00:56, 4462.86it/s]\u001b[A\n",
      " 39%|███▉      | 163047/414113 [00:37<00:56, 4437.10it/s]\u001b[A\n",
      " 39%|███▉      | 163500/414113 [00:37<00:56, 4462.62it/s]\u001b[A\n",
      " 40%|███▉      | 163947/414113 [00:37<00:56, 4402.86it/s]\u001b[A\n",
      " 40%|███▉      | 164388/414113 [00:38<00:56, 4384.44it/s]\u001b[A\n",
      " 40%|███▉      | 164827/414113 [00:38<00:57, 4337.84it/s]\u001b[A\n",
      " 40%|███▉      | 165270/414113 [00:38<00:57, 4364.49it/s]\u001b[A\n",
      " 40%|████      | 165707/414113 [00:38<00:57, 4346.52it/s]\u001b[A\n",
      " 40%|████      | 166142/414113 [00:38<00:57, 4296.69it/s]\u001b[A\n",
      " 40%|████      | 166572/414113 [00:38<00:58, 4266.97it/s]\u001b[A\n",
      " 40%|████      | 167020/414113 [00:38<00:57, 4328.51it/s]\u001b[A\n",
      " 40%|████      | 167462/414113 [00:38<00:56, 4354.03it/s]\u001b[A\n",
      " 41%|████      | 167900/414113 [00:38<00:56, 4360.19it/s]\u001b[A\n",
      " 41%|████      | 168337/414113 [00:38<00:56, 4360.04it/s]\u001b[A\n",
      " 41%|████      | 168774/414113 [00:39<00:56, 4355.30it/s]\u001b[A\n",
      " 41%|████      | 169210/414113 [00:39<00:57, 4275.13it/s]\u001b[A\n",
      " 41%|████      | 169638/414113 [00:39<00:57, 4240.42it/s]\u001b[A\n",
      " 41%|████      | 170071/414113 [00:39<00:57, 4264.98it/s]\u001b[A\n",
      " 41%|████      | 170513/414113 [00:39<00:56, 4309.05it/s]\u001b[A\n",
      " 41%|████▏     | 170953/414113 [00:39<00:56, 4335.52it/s]\u001b[A\n",
      " 41%|████▏     | 171395/414113 [00:39<00:55, 4359.89it/s]\u001b[A\n",
      " 41%|████▏     | 171840/414113 [00:39<00:55, 4384.85it/s]\u001b[A\n",
      " 42%|████▏     | 172279/414113 [00:39<00:55, 4367.46it/s]\u001b[A\n",
      " 42%|████▏     | 172716/414113 [00:39<00:55, 4349.28it/s]\u001b[A\n",
      " 42%|████▏     | 173152/414113 [00:40<00:55, 4326.81it/s]\u001b[A\n",
      " 42%|████▏     | 173585/414113 [00:40<00:56, 4278.22it/s]\u001b[A\n",
      " 42%|████▏     | 174014/414113 [00:40<01:33, 2576.48it/s]\u001b[A\n",
      " 42%|████▏     | 174428/414113 [00:40<01:22, 2904.24it/s]\u001b[A\n",
      " 42%|████▏     | 174859/414113 [00:40<01:14, 3218.13it/s]\u001b[A\n",
      " 42%|████▏     | 175242/414113 [00:40<01:10, 3378.42it/s]\u001b[A\n",
      " 42%|████▏     | 175684/414113 [00:40<01:05, 3634.09it/s]\u001b[A\n",
      " 43%|████▎     | 176125/414113 [00:40<01:02, 3836.11it/s]\u001b[A\n",
      " 43%|████▎     | 176564/414113 [00:41<00:59, 3986.05it/s]\u001b[A\n",
      " 43%|████▎     | 177003/414113 [00:41<00:57, 4097.60it/s]\u001b[A\n",
      " 43%|████▎     | 177452/414113 [00:41<00:56, 4205.44it/s]\u001b[A\n",
      " 43%|████▎     | 177885/414113 [00:41<00:55, 4240.42it/s]\u001b[A\n",
      " 43%|████▎     | 178318/414113 [00:41<00:55, 4236.57it/s]\u001b[A\n",
      " 43%|████▎     | 178748/414113 [00:41<00:57, 4107.49it/s]\u001b[A\n",
      " 43%|████▎     | 179189/414113 [00:41<00:56, 4191.45it/s]\u001b[A\n",
      " 43%|████▎     | 179633/414113 [00:41<00:55, 4263.02it/s]\u001b[A\n",
      " 43%|████▎     | 180068/414113 [00:41<00:54, 4288.39it/s]\u001b[A\n",
      " 44%|████▎     | 180500/414113 [00:42<00:54, 4297.80it/s]\u001b[A\n",
      " 44%|████▎     | 180944/414113 [00:42<00:53, 4339.11it/s]\u001b[A\n",
      " 44%|████▍     | 181392/414113 [00:42<00:53, 4379.04it/s]\u001b[A\n",
      " 44%|████▍     | 181831/414113 [00:42<00:53, 4366.45it/s]\u001b[A\n",
      " 44%|████▍     | 182269/414113 [00:42<00:54, 4278.22it/s]\u001b[A\n",
      " 44%|████▍     | 182698/414113 [00:42<00:54, 4262.62it/s]\u001b[A\n",
      " 44%|████▍     | 183125/414113 [00:42<00:54, 4260.18it/s]\u001b[A\n",
      " 44%|████▍     | 183564/414113 [00:42<00:53, 4295.58it/s]\u001b[A\n",
      " 44%|████▍     | 184003/414113 [00:42<00:53, 4322.54it/s]\u001b[A\n",
      " 45%|████▍     | 184436/414113 [00:42<00:53, 4317.18it/s]\u001b[A\n",
      " 45%|████▍     | 184875/414113 [00:43<00:52, 4337.59it/s]\u001b[A\n",
      " 45%|████▍     | 185320/414113 [00:43<00:52, 4368.21it/s]\u001b[A\n",
      " 45%|████▍     | 185757/414113 [00:43<00:52, 4349.59it/s]\u001b[A\n",
      " 45%|████▍     | 186202/414113 [00:43<00:52, 4377.37it/s]\u001b[A\n",
      " 45%|████▌     | 186640/414113 [00:43<00:54, 4148.14it/s]\u001b[A\n",
      " 45%|████▌     | 187088/414113 [00:43<00:53, 4240.20it/s]\u001b[A\n",
      " 45%|████▌     | 187525/414113 [00:43<00:52, 4276.34it/s]\u001b[A\n",
      " 45%|████▌     | 187964/414113 [00:43<00:52, 4308.09it/s]\u001b[A\n",
      " 45%|████▌     | 188397/414113 [00:43<00:52, 4288.28it/s]\u001b[A\n",
      " 46%|████▌     | 188827/414113 [00:43<00:53, 4177.43it/s]\u001b[A\n",
      " 46%|████▌     | 189269/414113 [00:44<00:52, 4246.30it/s]\u001b[A\n",
      " 46%|████▌     | 189715/414113 [00:44<00:52, 4305.36it/s]\u001b[A\n",
      " 46%|████▌     | 190163/414113 [00:44<00:51, 4354.53it/s]\u001b[A\n",
      " 46%|████▌     | 190601/414113 [00:44<00:51, 4360.31it/s]\u001b[A\n",
      " 46%|████▌     | 191038/414113 [00:44<00:51, 4341.62it/s]\u001b[A\n",
      " 46%|████▌     | 191479/414113 [00:44<00:51, 4360.98it/s]\u001b[A\n",
      " 46%|████▋     | 191916/414113 [00:44<00:50, 4359.99it/s]\u001b[A\n",
      " 46%|████▋     | 192364/414113 [00:44<00:50, 4394.23it/s]\u001b[A\n",
      " 47%|████▋     | 192804/414113 [00:44<00:50, 4366.94it/s]\u001b[A\n",
      " 47%|████▋     | 193241/414113 [00:44<00:50, 4347.77it/s]\u001b[A\n",
      " 47%|████▋     | 193686/414113 [00:45<00:50, 4376.17it/s]\u001b[A\n",
      " 47%|████▋     | 194129/414113 [00:45<00:50, 4391.92it/s]\u001b[A\n",
      " 47%|████▋     | 194569/414113 [00:45<00:50, 4372.15it/s]\u001b[A\n",
      " 47%|████▋     | 195013/414113 [00:45<00:49, 4388.21it/s]\u001b[A\n",
      " 47%|████▋     | 195452/414113 [00:45<00:49, 4380.95it/s]\u001b[A\n",
      " 47%|████▋     | 195891/414113 [00:45<00:50, 4338.82it/s]\u001b[A\n",
      " 47%|████▋     | 196335/414113 [00:45<00:49, 4367.03it/s]\u001b[A\n",
      " 48%|████▊     | 196772/414113 [00:45<00:50, 4345.75it/s]\u001b[A\n",
      " 48%|████▊     | 197207/414113 [00:45<00:51, 4245.72it/s]\u001b[A\n",
      " 48%|████▊     | 197657/414113 [00:45<00:50, 4318.04it/s]\u001b[A\n",
      " 48%|████▊     | 198101/414113 [00:46<00:49, 4353.20it/s]\u001b[A\n",
      " 48%|████▊     | 198546/414113 [00:46<00:49, 4381.38it/s]\u001b[A\n",
      " 48%|████▊     | 198985/414113 [00:46<00:49, 4374.73it/s]\u001b[A\n",
      " 48%|████▊     | 199426/414113 [00:46<00:48, 4385.02it/s]\u001b[A\n",
      " 48%|████▊     | 199865/414113 [00:46<00:49, 4348.13it/s]\u001b[A\n",
      " 48%|████▊     | 200312/414113 [00:46<00:48, 4382.20it/s]\u001b[A\n",
      " 48%|████▊     | 200755/414113 [00:46<00:48, 4396.21it/s]\u001b[A\n",
      " 49%|████▊     | 201205/414113 [00:46<00:48, 4424.88it/s]\u001b[A\n",
      " 49%|████▊     | 201648/414113 [00:46<00:48, 4420.86it/s]\u001b[A\n",
      " 49%|████▉     | 202093/414113 [00:46<00:47, 4427.39it/s]\u001b[A\n",
      " 49%|████▉     | 202536/414113 [00:47<00:47, 4409.97it/s]\u001b[A\n",
      " 49%|████▉     | 202978/414113 [00:47<00:47, 4409.43it/s]\u001b[A\n",
      " 49%|████▉     | 203423/414113 [00:47<00:47, 4419.65it/s]\u001b[A\n",
      " 49%|████▉     | 203866/414113 [00:47<00:47, 4412.06it/s]\u001b[A\n",
      " 49%|████▉     | 204308/414113 [00:47<00:47, 4375.50it/s]\u001b[A\n",
      " 49%|████▉     | 204752/414113 [00:47<00:47, 4394.42it/s]\u001b[A\n",
      " 50%|████▉     | 205192/414113 [00:47<00:47, 4395.78it/s]\u001b[A\n",
      " 50%|████▉     | 205632/414113 [00:47<00:47, 4389.07it/s]\u001b[A\n",
      " 50%|████▉     | 206071/414113 [00:47<00:47, 4356.08it/s]\u001b[A\n",
      " 50%|████▉     | 206513/414113 [00:47<00:47, 4374.13it/s]\u001b[A\n",
      " 50%|████▉     | 206951/414113 [00:48<00:47, 4367.38it/s]\u001b[A\n",
      " 50%|█████     | 207388/414113 [00:48<00:47, 4355.12it/s]\u001b[A\n",
      " 50%|█████     | 207835/414113 [00:48<00:47, 4387.71it/s]\u001b[A\n",
      " 50%|█████     | 208277/414113 [00:48<00:46, 4395.97it/s]\u001b[A\n",
      " 50%|█████     | 208717/414113 [00:48<00:47, 4321.35it/s]\u001b[A\n",
      " 51%|█████     | 209156/414113 [00:48<00:47, 4340.31it/s]\u001b[A\n",
      " 51%|█████     | 209596/414113 [00:48<00:46, 4355.89it/s]\u001b[A\n",
      " 51%|█████     | 210041/414113 [00:48<00:46, 4381.36it/s]\u001b[A\n",
      " 51%|█████     | 210480/414113 [00:48<00:46, 4368.58it/s]\u001b[A\n",
      " 51%|█████     | 210925/414113 [00:49<00:46, 4390.80it/s]\u001b[A\n",
      " 51%|█████     | 211379/414113 [00:49<00:45, 4432.02it/s]\u001b[A\n",
      " 51%|█████     | 211828/414113 [00:49<00:45, 4448.76it/s]\u001b[A\n",
      " 51%|█████▏    | 212274/414113 [00:49<00:45, 4441.41it/s]\u001b[A\n",
      " 51%|█████▏    | 212719/414113 [00:49<00:46, 4346.01it/s]\u001b[A\n",
      " 51%|█████▏    | 213164/414113 [00:49<00:45, 4376.62it/s]\u001b[A\n",
      " 52%|█████▏    | 213603/414113 [00:49<00:45, 4371.41it/s]\u001b[A\n",
      " 52%|█████▏    | 214041/414113 [00:49<00:45, 4367.84it/s]\u001b[A\n",
      " 52%|█████▏    | 214493/414113 [00:49<00:45, 4410.18it/s]\u001b[A\n",
      " 52%|█████▏    | 214936/414113 [00:49<00:45, 4413.99it/s]\u001b[A\n",
      " 52%|█████▏    | 215380/414113 [00:50<00:44, 4420.34it/s]\u001b[A\n",
      " 52%|█████▏    | 215823/414113 [00:50<00:45, 4343.57it/s]\u001b[A\n",
      " 52%|█████▏    | 216263/414113 [00:50<00:45, 4360.04it/s]\u001b[A\n",
      " 52%|█████▏    | 216705/414113 [00:50<00:45, 4374.93it/s]\u001b[A\n",
      " 52%|█████▏    | 217143/414113 [00:50<00:45, 4358.36it/s]\u001b[A\n",
      " 53%|█████▎    | 217583/414113 [00:50<00:44, 4368.69it/s]\u001b[A\n",
      " 53%|█████▎    | 218040/414113 [00:50<00:44, 4424.75it/s]\u001b[A\n",
      " 53%|█████▎    | 218484/414113 [00:50<00:44, 4427.91it/s]\u001b[A\n",
      " 53%|█████▎    | 218929/414113 [00:50<00:44, 4433.82it/s]\u001b[A\n",
      " 53%|█████▎    | 219376/414113 [00:50<00:43, 4442.74it/s]\u001b[A\n",
      " 53%|█████▎    | 219821/414113 [00:51<00:43, 4439.27it/s]\u001b[A\n",
      " 53%|█████▎    | 220265/414113 [00:51<00:43, 4438.42it/s]\u001b[A\n",
      " 53%|█████▎    | 220712/414113 [00:51<00:43, 4444.99it/s]\u001b[A\n",
      " 53%|█████▎    | 221157/414113 [00:51<00:43, 4405.64it/s]\u001b[A\n",
      " 54%|█████▎    | 221598/414113 [00:51<00:44, 4280.98it/s]\u001b[A\n",
      " 54%|█████▎    | 222052/414113 [00:51<00:44, 4353.14it/s]\u001b[A\n",
      " 54%|█████▎    | 222493/414113 [00:51<00:43, 4368.53it/s]\u001b[A\n",
      " 54%|█████▍    | 222953/414113 [00:51<00:43, 4433.87it/s]\u001b[A\n",
      " 54%|█████▍    | 223398/414113 [00:51<00:42, 4438.64it/s]\u001b[A\n",
      " 54%|█████▍    | 223849/414113 [00:51<00:42, 4457.87it/s]\u001b[A\n",
      " 54%|█████▍    | 224306/414113 [00:52<00:42, 4490.36it/s]\u001b[A\n",
      " 54%|█████▍    | 224756/414113 [00:52<00:42, 4472.77it/s]\u001b[A\n",
      " 54%|█████▍    | 225208/414113 [00:52<00:42, 4486.20it/s]\u001b[A\n",
      " 54%|█████▍    | 225657/414113 [00:52<00:41, 4487.19it/s]\u001b[A\n",
      " 55%|█████▍    | 226106/414113 [00:52<00:42, 4413.69it/s]\u001b[A\n",
      " 55%|█████▍    | 226548/414113 [00:52<00:42, 4410.76it/s]\u001b[A\n",
      " 55%|█████▍    | 226997/414113 [00:52<00:42, 4432.80it/s]\u001b[A\n",
      " 55%|█████▍    | 227441/414113 [00:52<00:42, 4402.83it/s]\u001b[A\n",
      " 55%|█████▌    | 227904/414113 [00:52<00:41, 4466.97it/s]\u001b[A\n",
      " 55%|█████▌    | 228352/414113 [00:52<00:41, 4458.41it/s]\u001b[A\n",
      " 55%|█████▌    | 228807/414113 [00:53<00:41, 4484.62it/s]\u001b[A\n",
      " 55%|█████▌    | 229256/414113 [00:53<00:41, 4442.65it/s]\u001b[A\n",
      " 55%|█████▌    | 229701/414113 [00:53<00:41, 4441.11it/s]\u001b[A\n",
      " 56%|█████▌    | 230146/414113 [00:53<00:41, 4397.75it/s]\u001b[A\n",
      " 56%|█████▌    | 230586/414113 [00:53<00:41, 4377.37it/s]\u001b[A\n",
      " 56%|█████▌    | 231024/414113 [00:53<00:42, 4337.97it/s]\u001b[A\n",
      " 56%|█████▌    | 231458/414113 [00:53<00:42, 4285.18it/s]\u001b[A\n",
      " 56%|█████▌    | 231892/414113 [00:53<00:42, 4298.77it/s]\u001b[A\n",
      " 56%|█████▌    | 232323/414113 [00:53<00:42, 4244.55it/s]\u001b[A\n",
      " 56%|█████▌    | 232754/414113 [00:53<00:42, 4261.39it/s]\u001b[A\n",
      " 56%|█████▋    | 233183/414113 [00:54<00:42, 4269.87it/s]\u001b[A\n",
      " 56%|█████▋    | 233618/414113 [00:54<00:42, 4292.62it/s]\u001b[A\n",
      " 57%|█████▋    | 234061/414113 [00:54<00:41, 4331.66it/s]\u001b[A\n",
      " 57%|█████▋    | 234495/414113 [00:54<00:41, 4310.59it/s]\u001b[A\n",
      " 57%|█████▋    | 234929/414113 [00:54<00:41, 4318.26it/s]\u001b[A\n",
      " 57%|█████▋    | 235361/414113 [00:54<00:42, 4251.60it/s]\u001b[A\n",
      " 57%|█████▋    | 235787/414113 [00:54<00:41, 4253.80it/s]\u001b[A\n",
      " 57%|█████▋    | 236232/414113 [00:54<00:41, 4309.24it/s]\u001b[A\n",
      " 57%|█████▋    | 236664/414113 [00:54<00:41, 4304.21it/s]\u001b[A\n",
      " 57%|█████▋    | 237095/414113 [00:54<00:41, 4304.91it/s]\u001b[A\n",
      " 57%|█████▋    | 237538/414113 [00:55<00:40, 4340.35it/s]\u001b[A\n",
      " 57%|█████▋    | 237973/414113 [00:55<00:40, 4334.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 238408/414113 [00:55<00:40, 4337.95it/s]\u001b[A\n",
      " 58%|█████▊    | 238843/414113 [00:55<00:40, 4340.77it/s]\u001b[A\n",
      " 58%|█████▊    | 239282/414113 [00:55<00:40, 4354.03it/s]\u001b[A\n",
      " 58%|█████▊    | 239718/414113 [00:55<00:40, 4323.62it/s]\u001b[A\n",
      " 58%|█████▊    | 240151/414113 [00:55<00:40, 4319.82it/s]\u001b[A\n",
      " 58%|█████▊    | 240584/414113 [00:55<00:40, 4307.95it/s]\u001b[A\n",
      " 58%|█████▊    | 241020/414113 [00:55<00:40, 4321.21it/s]\u001b[A\n",
      " 58%|█████▊    | 241453/414113 [00:55<00:39, 4323.79it/s]\u001b[A\n",
      " 58%|█████▊    | 241901/414113 [00:56<00:39, 4367.63it/s]\u001b[A\n",
      " 59%|█████▊    | 242338/414113 [00:56<00:39, 4350.78it/s]\u001b[A\n",
      " 59%|█████▊    | 242783/414113 [00:56<00:39, 4379.28it/s]\u001b[A\n",
      " 59%|█████▊    | 243222/414113 [00:56<00:39, 4346.40it/s]\u001b[A\n",
      " 59%|█████▉    | 243657/414113 [00:56<00:39, 4339.12it/s]\u001b[A\n",
      " 59%|█████▉    | 244095/414113 [00:56<00:39, 4348.97it/s]\u001b[A\n",
      " 59%|█████▉    | 244532/414113 [00:56<00:38, 4353.90it/s]\u001b[A\n",
      " 59%|█████▉    | 244981/414113 [00:56<00:38, 4393.23it/s]\u001b[A\n",
      " 59%|█████▉    | 245421/414113 [00:56<00:38, 4368.42it/s]\u001b[A\n",
      " 59%|█████▉    | 245861/414113 [00:56<00:38, 4376.23it/s]\u001b[A\n",
      " 59%|█████▉    | 246299/414113 [00:57<00:38, 4372.87it/s]\u001b[A\n",
      " 60%|█████▉    | 246737/414113 [00:57<00:40, 4096.57it/s]\u001b[A\n",
      " 60%|█████▉    | 247174/414113 [00:57<00:40, 4171.79it/s]\u001b[A\n",
      " 60%|█████▉    | 247605/414113 [00:57<00:39, 4210.42it/s]\u001b[A\n",
      " 60%|█████▉    | 248035/414113 [00:57<00:39, 4234.69it/s]\u001b[A\n",
      " 60%|██████    | 248469/414113 [00:57<00:38, 4263.39it/s]\u001b[A\n",
      " 60%|██████    | 248898/414113 [00:57<00:38, 4270.45it/s]\u001b[A\n",
      " 60%|██████    | 249328/414113 [00:57<00:38, 4277.20it/s]\u001b[A\n",
      " 60%|██████    | 249775/414113 [00:57<00:37, 4331.25it/s]\u001b[A\n",
      " 60%|██████    | 250214/414113 [00:58<00:37, 4345.77it/s]\u001b[A\n",
      " 61%|██████    | 250649/414113 [00:58<00:37, 4315.98it/s]\u001b[A\n",
      " 61%|██████    | 251092/414113 [00:58<00:37, 4347.23it/s]\u001b[A\n",
      " 61%|██████    | 251532/414113 [00:58<00:37, 4361.88it/s]\u001b[A\n",
      " 61%|██████    | 251973/414113 [00:58<00:37, 4376.09it/s]\u001b[A\n",
      " 61%|██████    | 252411/414113 [00:58<00:37, 4300.44it/s]\u001b[A\n",
      " 61%|██████    | 252842/414113 [00:58<00:37, 4287.57it/s]\u001b[A\n",
      " 61%|██████    | 253286/414113 [00:58<00:37, 4331.92it/s]\u001b[A\n",
      " 61%|██████▏   | 253720/414113 [00:58<00:37, 4324.16it/s]\u001b[A\n",
      " 61%|██████▏   | 254153/414113 [00:58<00:37, 4270.37it/s]\u001b[A\n",
      " 61%|██████▏   | 254589/414113 [00:59<00:37, 4294.31it/s]\u001b[A\n",
      " 62%|██████▏   | 255019/414113 [00:59<00:37, 4255.84it/s]\u001b[A\n",
      " 62%|██████▏   | 255445/414113 [00:59<00:37, 4214.37it/s]\u001b[A\n",
      " 62%|██████▏   | 255884/414113 [00:59<00:37, 4264.57it/s]\u001b[A\n",
      " 62%|██████▏   | 256328/414113 [00:59<00:36, 4315.39it/s]\u001b[A\n",
      " 62%|██████▏   | 256765/414113 [00:59<00:36, 4329.90it/s]\u001b[A\n",
      " 62%|██████▏   | 257203/414113 [00:59<00:36, 4343.99it/s]\u001b[A\n",
      " 62%|██████▏   | 257648/414113 [00:59<00:35, 4372.75it/s]\u001b[A\n",
      " 62%|██████▏   | 258086/414113 [00:59<00:35, 4361.31it/s]\u001b[A\n",
      " 62%|██████▏   | 258523/414113 [00:59<00:36, 4295.20it/s]\u001b[A\n",
      " 63%|██████▎   | 258959/414113 [01:00<00:35, 4313.60it/s]\u001b[A\n",
      " 63%|██████▎   | 259397/414113 [01:00<00:35, 4331.63it/s]\u001b[A\n",
      " 63%|██████▎   | 259838/414113 [01:00<00:35, 4354.78it/s]\u001b[A\n",
      " 63%|██████▎   | 260274/414113 [01:00<00:35, 4333.11it/s]\u001b[A\n",
      " 63%|██████▎   | 260709/414113 [01:00<00:35, 4336.75it/s]\u001b[A\n",
      " 63%|██████▎   | 261143/414113 [01:00<00:35, 4314.19it/s]\u001b[A\n",
      " 63%|██████▎   | 261588/414113 [01:00<00:35, 4351.79it/s]\u001b[A\n",
      " 63%|██████▎   | 262028/414113 [01:00<00:34, 4363.61it/s]\u001b[A\n",
      " 63%|██████▎   | 262467/414113 [01:00<00:34, 4369.62it/s]\u001b[A\n",
      " 63%|██████▎   | 262905/414113 [01:00<00:34, 4370.35it/s]\u001b[A\n",
      " 64%|██████▎   | 263343/414113 [01:01<00:34, 4354.56it/s]\u001b[A\n",
      " 64%|██████▎   | 263780/414113 [01:01<00:34, 4356.94it/s]\u001b[A\n",
      " 64%|██████▍   | 264218/414113 [01:01<00:34, 4363.63it/s]\u001b[A\n",
      " 64%|██████▍   | 264655/414113 [01:01<00:34, 4341.21it/s]\u001b[A\n",
      " 64%|██████▍   | 265090/414113 [01:01<00:34, 4334.03it/s]\u001b[A\n",
      " 64%|██████▍   | 265524/414113 [01:01<00:34, 4298.37it/s]\u001b[A\n",
      " 64%|██████▍   | 265964/414113 [01:01<00:34, 4325.33it/s]\u001b[A\n",
      " 64%|██████▍   | 266408/414113 [01:01<00:33, 4357.28it/s]\u001b[A\n",
      " 64%|██████▍   | 266851/414113 [01:01<00:33, 4377.06it/s]\u001b[A\n",
      " 65%|██████▍   | 267293/414113 [01:01<00:33, 4388.91it/s]\u001b[A\n",
      " 65%|██████▍   | 267732/414113 [01:02<00:33, 4388.61it/s]\u001b[A\n",
      " 65%|██████▍   | 268176/414113 [01:02<00:33, 4401.29it/s]\u001b[A\n",
      " 65%|██████▍   | 268617/414113 [01:02<00:33, 4388.14it/s]\u001b[A\n",
      " 65%|██████▍   | 269056/414113 [01:02<00:33, 4361.71it/s]\u001b[A\n",
      " 65%|██████▌   | 269493/414113 [01:02<00:33, 4295.98it/s]\u001b[A\n",
      " 65%|██████▌   | 269923/414113 [01:02<00:33, 4295.04it/s]\u001b[A\n",
      " 65%|██████▌   | 270355/414113 [01:02<00:33, 4302.08it/s]\u001b[A\n",
      " 65%|██████▌   | 270790/414113 [01:02<00:33, 4314.25it/s]\u001b[A\n",
      " 65%|██████▌   | 271230/414113 [01:02<00:32, 4338.09it/s]\u001b[A\n",
      " 66%|██████▌   | 271664/414113 [01:02<00:32, 4327.03it/s]\u001b[A\n",
      " 66%|██████▌   | 272097/414113 [01:03<00:32, 4314.38it/s]\u001b[A\n",
      " 66%|██████▌   | 272533/414113 [01:03<00:32, 4325.16it/s]\u001b[A\n",
      " 66%|██████▌   | 272974/414113 [01:03<00:32, 4347.64it/s]\u001b[A\n",
      " 66%|██████▌   | 273409/414113 [01:03<00:32, 4301.96it/s]\u001b[A\n",
      " 66%|██████▌   | 273840/414113 [01:03<00:32, 4277.39it/s]\u001b[A\n",
      " 66%|██████▌   | 274274/414113 [01:03<00:32, 4295.54it/s]\u001b[A\n",
      " 66%|██████▋   | 274722/414113 [01:03<00:32, 4348.47it/s]\u001b[A\n",
      " 66%|██████▋   | 275162/414113 [01:03<00:31, 4361.76it/s]\u001b[A\n",
      " 67%|██████▋   | 275607/414113 [01:03<00:31, 4384.58it/s]\u001b[A\n",
      " 67%|██████▋   | 276054/414113 [01:03<00:31, 4408.09it/s]\u001b[A\n",
      " 67%|██████▋   | 276501/414113 [01:04<00:31, 4426.07it/s]\u001b[A\n",
      " 67%|██████▋   | 276944/414113 [01:04<00:30, 4425.81it/s]\u001b[A\n",
      " 67%|██████▋   | 277387/414113 [01:04<00:31, 4403.56it/s]\u001b[A\n",
      " 67%|██████▋   | 277828/414113 [01:04<00:31, 4393.18it/s]\u001b[A\n",
      " 67%|██████▋   | 278268/414113 [01:04<00:31, 4327.48it/s]\u001b[A\n",
      " 67%|██████▋   | 278702/414113 [01:04<00:31, 4313.76it/s]\u001b[A\n",
      " 67%|██████▋   | 279134/414113 [01:04<00:31, 4307.78it/s]\u001b[A\n",
      " 68%|██████▊   | 279578/414113 [01:04<00:30, 4344.95it/s]\u001b[A\n",
      " 68%|██████▊   | 280013/414113 [01:04<00:30, 4330.07it/s]\u001b[A\n",
      " 68%|██████▊   | 280458/414113 [01:04<00:30, 4364.33it/s]\u001b[A\n",
      " 68%|██████▊   | 280895/414113 [01:05<00:30, 4350.58it/s]\u001b[A\n",
      " 68%|██████▊   | 281334/414113 [01:05<00:30, 4362.30it/s]\u001b[A\n",
      " 68%|██████▊   | 281771/414113 [01:05<00:30, 4328.36it/s]\u001b[A\n",
      " 68%|██████▊   | 282204/414113 [01:05<00:30, 4324.35it/s]\u001b[A\n",
      " 68%|██████▊   | 282646/414113 [01:05<00:30, 4351.07it/s]\u001b[A\n",
      " 68%|██████▊   | 283084/414113 [01:05<00:30, 4358.17it/s]\u001b[A\n",
      " 68%|██████▊   | 283526/414113 [01:05<00:29, 4376.51it/s]\u001b[A\n",
      " 69%|██████▊   | 283964/414113 [01:05<00:29, 4366.98it/s]\u001b[A\n",
      " 69%|██████▊   | 284401/414113 [01:05<00:29, 4338.40it/s]\u001b[A\n",
      " 69%|██████▉   | 284850/414113 [01:05<00:29, 4381.24it/s]\u001b[A\n",
      " 69%|██████▉   | 285299/414113 [01:06<00:29, 4412.88it/s]\u001b[A\n",
      " 69%|██████▉   | 285745/414113 [01:06<00:29, 4426.09it/s]\u001b[A\n",
      " 69%|██████▉   | 286189/414113 [01:06<00:28, 4427.60it/s]\u001b[A\n",
      " 69%|██████▉   | 286632/414113 [01:06<00:28, 4409.10it/s]\u001b[A\n",
      " 69%|██████▉   | 287078/414113 [01:06<00:28, 4424.16it/s]\u001b[A\n",
      " 69%|██████▉   | 287521/414113 [01:06<00:28, 4395.96it/s]\u001b[A\n",
      " 70%|██████▉   | 287961/414113 [01:06<00:29, 4317.58it/s]\u001b[A\n",
      " 70%|██████▉   | 288405/414113 [01:06<00:28, 4351.82it/s]\u001b[A\n",
      " 70%|██████▉   | 288851/414113 [01:06<00:28, 4383.52it/s]\u001b[A\n",
      " 70%|██████▉   | 289290/414113 [01:07<00:28, 4372.13it/s]\u001b[A\n",
      " 70%|██████▉   | 289728/414113 [01:07<00:28, 4350.36it/s]\u001b[A\n",
      " 70%|███████   | 290171/414113 [01:07<00:28, 4373.59it/s]\u001b[A\n",
      " 70%|███████   | 290614/414113 [01:07<00:28, 4389.85it/s]\u001b[A\n",
      " 70%|███████   | 291054/414113 [01:07<00:28, 4374.67it/s]\u001b[A\n",
      " 70%|███████   | 291499/414113 [01:07<00:27, 4394.29it/s]\u001b[A\n",
      " 70%|███████   | 291945/414113 [01:07<00:27, 4412.02it/s]\u001b[A\n",
      " 71%|███████   | 292387/414113 [01:07<00:27, 4411.59it/s]\u001b[A\n",
      " 71%|███████   | 292829/414113 [01:07<00:27, 4396.30it/s]\u001b[A\n",
      " 71%|███████   | 293282/414113 [01:07<00:27, 4433.59it/s]\u001b[A\n",
      " 71%|███████   | 293726/414113 [01:08<00:27, 4302.78it/s]\u001b[A\n",
      " 71%|███████   | 294169/414113 [01:08<00:27, 4340.03it/s]\u001b[A\n",
      " 71%|███████   | 294609/414113 [01:08<00:27, 4355.38it/s]\u001b[A\n",
      " 71%|███████   | 295046/414113 [01:08<00:27, 4333.32it/s]\u001b[A\n",
      " 71%|███████▏  | 295481/414113 [01:08<00:27, 4337.25it/s]\u001b[A\n",
      " 71%|███████▏  | 295927/414113 [01:08<00:27, 4372.04it/s]\u001b[A\n",
      " 72%|███████▏  | 296365/414113 [01:08<00:26, 4363.25it/s]\u001b[A\n",
      " 72%|███████▏  | 296802/414113 [01:08<00:27, 4323.33it/s]\u001b[A\n",
      " 72%|███████▏  | 297240/414113 [01:08<00:26, 4337.80it/s]\u001b[A\n",
      " 72%|███████▏  | 297674/414113 [01:08<00:27, 4311.66it/s]\u001b[A\n",
      " 72%|███████▏  | 298111/414113 [01:09<00:26, 4325.90it/s]\u001b[A\n",
      " 72%|███████▏  | 298553/414113 [01:09<00:26, 4350.84it/s]\u001b[A\n",
      " 72%|███████▏  | 298989/414113 [01:09<00:26, 4324.21it/s]\u001b[A\n",
      " 72%|███████▏  | 299422/414113 [01:09<00:47, 2429.57it/s]\u001b[A\n",
      " 72%|███████▏  | 299863/414113 [01:09<00:40, 2807.37it/s]\u001b[A\n",
      " 73%|███████▎  | 300305/414113 [01:09<00:36, 3151.94it/s]\u001b[A\n",
      " 73%|███████▎  | 300721/414113 [01:09<00:33, 3397.43it/s]\u001b[A\n",
      " 73%|███████▎  | 301159/414113 [01:09<00:31, 3642.56it/s]\u001b[A\n",
      " 73%|███████▎  | 301595/414113 [01:10<00:29, 3830.78it/s]\u001b[A\n",
      " 73%|███████▎  | 302042/414113 [01:10<00:28, 4000.91it/s]\u001b[A\n",
      " 73%|███████▎  | 302481/414113 [01:10<00:27, 4108.79it/s]\u001b[A\n",
      " 73%|███████▎  | 302918/414113 [01:10<00:26, 4183.59it/s]\u001b[A\n",
      " 73%|███████▎  | 303356/414113 [01:10<00:26, 4239.68it/s]\u001b[A\n",
      " 73%|███████▎  | 303790/414113 [01:10<00:25, 4250.39it/s]\u001b[A\n",
      " 73%|███████▎  | 304226/414113 [01:10<00:25, 4280.72it/s]\u001b[A\n",
      " 74%|███████▎  | 304667/414113 [01:10<00:25, 4317.41it/s]\u001b[A\n",
      " 74%|███████▎  | 305103/414113 [01:10<00:25, 4313.29it/s]\u001b[A\n",
      " 74%|███████▍  | 305537/414113 [01:10<00:25, 4295.62it/s]\u001b[A\n",
      " 74%|███████▍  | 305969/414113 [01:11<00:25, 4270.97it/s]\u001b[A\n",
      " 74%|███████▍  | 306398/414113 [01:11<00:25, 4239.66it/s]\u001b[A\n",
      " 74%|███████▍  | 306832/414113 [01:11<00:25, 4266.81it/s]\u001b[A\n",
      " 74%|███████▍  | 307260/414113 [01:11<00:25, 4225.92it/s]\u001b[A\n",
      " 74%|███████▍  | 307690/414113 [01:11<00:25, 4247.59it/s]\u001b[A\n",
      " 74%|███████▍  | 308126/414113 [01:11<00:24, 4279.45it/s]\u001b[A\n",
      " 75%|███████▍  | 308562/414113 [01:11<00:24, 4301.50it/s]\u001b[A\n",
      " 75%|███████▍  | 309002/414113 [01:11<00:24, 4328.13it/s]\u001b[A\n",
      " 75%|███████▍  | 309444/414113 [01:11<00:24, 4352.05it/s]\u001b[A\n",
      " 75%|███████▍  | 309887/414113 [01:12<00:23, 4374.38it/s]\u001b[A\n",
      " 75%|███████▍  | 310325/414113 [01:12<00:23, 4354.24it/s]\u001b[A\n",
      " 75%|███████▌  | 310765/414113 [01:12<00:23, 4365.77it/s]\u001b[A\n",
      " 75%|███████▌  | 311202/414113 [01:12<00:23, 4351.61it/s]\u001b[A\n",
      " 75%|███████▌  | 311638/414113 [01:12<00:23, 4328.54it/s]\u001b[A\n",
      " 75%|███████▌  | 312077/414113 [01:12<00:23, 4345.01it/s]\u001b[A\n",
      " 75%|███████▌  | 312521/414113 [01:12<00:23, 4371.06it/s]\u001b[A\n",
      " 76%|███████▌  | 312960/414113 [01:12<00:23, 4376.23it/s]\u001b[A\n",
      " 76%|███████▌  | 313402/414113 [01:12<00:22, 4388.37it/s]\u001b[A\n",
      " 76%|███████▌  | 313842/414113 [01:12<00:22, 4390.58it/s]\u001b[A\n",
      " 76%|███████▌  | 314291/414113 [01:13<00:22, 4419.07it/s]\u001b[A\n",
      " 76%|███████▌  | 314733/414113 [01:13<00:22, 4407.42it/s]\u001b[A\n",
      " 76%|███████▌  | 315181/414113 [01:13<00:22, 4427.59it/s]\u001b[A\n",
      " 76%|███████▌  | 315624/414113 [01:13<00:22, 4413.54it/s]\u001b[A\n",
      " 76%|███████▋  | 316066/414113 [01:13<00:22, 4385.74it/s]\u001b[A\n",
      " 76%|███████▋  | 316505/414113 [01:13<00:24, 4028.88it/s]\u001b[A\n",
      " 77%|███████▋  | 316944/414113 [01:13<00:23, 4129.02it/s]\u001b[A\n",
      " 77%|███████▋  | 317392/414113 [01:13<00:22, 4226.42it/s]\u001b[A\n",
      " 77%|███████▋  | 317829/414113 [01:13<00:22, 4267.69it/s]\u001b[A\n",
      " 77%|███████▋  | 318265/414113 [01:13<00:22, 4293.97it/s]\u001b[A\n",
      " 77%|███████▋  | 318713/414113 [01:14<00:21, 4348.01it/s]\u001b[A\n",
      " 77%|███████▋  | 319164/414113 [01:14<00:21, 4392.89it/s]\u001b[A\n",
      " 77%|███████▋  | 319605/414113 [01:14<00:21, 4373.45it/s]\u001b[A\n",
      " 77%|███████▋  | 320044/414113 [01:14<00:21, 4339.99it/s]\u001b[A\n",
      " 77%|███████▋  | 320483/414113 [01:14<00:21, 4354.01it/s]\u001b[A\n",
      " 77%|███████▋  | 320919/414113 [01:14<00:21, 4354.86it/s]\u001b[A\n",
      " 78%|███████▊  | 321362/414113 [01:14<00:21, 4375.54it/s]\u001b[A\n",
      " 78%|███████▊  | 321800/414113 [01:14<00:21, 4376.83it/s]\u001b[A\n",
      " 78%|███████▊  | 322244/414113 [01:14<00:20, 4395.41it/s]\u001b[A\n",
      " 78%|███████▊  | 322689/414113 [01:14<00:20, 4410.94it/s]\u001b[A\n",
      " 78%|███████▊  | 323136/414113 [01:15<00:20, 4427.48it/s]\u001b[A\n",
      " 78%|███████▊  | 323579/414113 [01:15<00:20, 4360.12it/s]\u001b[A\n",
      " 78%|███████▊  | 324024/414113 [01:15<00:20, 4386.00it/s]\u001b[A\n",
      " 78%|███████▊  | 324463/414113 [01:15<00:20, 4351.25it/s]\u001b[A\n",
      " 78%|███████▊  | 324920/414113 [01:15<00:20, 4413.87it/s]\u001b[A\n",
      " 79%|███████▊  | 325362/414113 [01:15<00:20, 4380.74it/s]\u001b[A\n",
      " 79%|███████▊  | 325815/414113 [01:15<00:19, 4423.84it/s]\u001b[A\n",
      " 79%|███████▉  | 326258/414113 [01:15<00:20, 4369.70it/s]\u001b[A\n",
      " 79%|███████▉  | 326700/414113 [01:15<00:19, 4382.46it/s]\u001b[A\n",
      " 79%|███████▉  | 327139/414113 [01:15<00:19, 4372.91it/s]\u001b[A\n",
      " 79%|███████▉  | 327579/414113 [01:16<00:19, 4380.33it/s]\u001b[A\n",
      " 79%|███████▉  | 328019/414113 [01:16<00:19, 4383.90it/s]\u001b[A\n",
      " 79%|███████▉  | 328460/414113 [01:16<00:19, 4389.74it/s]\u001b[A\n",
      " 79%|███████▉  | 328900/414113 [01:16<00:19, 4357.60it/s]\u001b[A\n",
      " 80%|███████▉  | 329336/414113 [01:16<00:19, 4311.06it/s]\u001b[A\n",
      " 80%|███████▉  | 329768/414113 [01:16<00:19, 4258.31it/s]\u001b[A\n",
      " 80%|███████▉  | 330195/414113 [01:16<00:19, 4259.45it/s]\u001b[A\n",
      " 80%|███████▉  | 330626/414113 [01:16<00:19, 4274.42it/s]\u001b[A\n",
      " 80%|███████▉  | 331054/414113 [01:16<00:19, 4238.66it/s]\u001b[A\n",
      " 80%|████████  | 331479/414113 [01:16<00:19, 4213.00it/s]\u001b[A\n",
      " 80%|████████  | 331916/414113 [01:17<00:19, 4255.33it/s]\u001b[A\n",
      " 80%|████████  | 332351/414113 [01:17<00:19, 4283.16it/s]\u001b[A\n",
      " 80%|████████  | 332780/414113 [01:17<00:18, 4284.95it/s]\u001b[A\n",
      " 80%|████████  | 333212/414113 [01:17<00:18, 4294.47it/s]\u001b[A\n",
      " 81%|████████  | 333642/414113 [01:17<00:18, 4288.28it/s]\u001b[A\n",
      " 81%|████████  | 334076/414113 [01:17<00:18, 4303.22it/s]\u001b[A\n",
      " 81%|████████  | 334518/414113 [01:17<00:18, 4337.60it/s]\u001b[A\n",
      " 81%|████████  | 334957/414113 [01:17<00:18, 4350.97it/s]\u001b[A\n",
      " 81%|████████  | 335393/414113 [01:17<00:18, 4327.95it/s]\u001b[A\n",
      " 81%|████████  | 335827/414113 [01:17<00:18, 4330.40it/s]\u001b[A\n",
      " 81%|████████  | 336261/414113 [01:18<00:17, 4330.87it/s]\u001b[A\n",
      " 81%|████████▏ | 336697/414113 [01:18<00:17, 4337.26it/s]\u001b[A\n",
      " 81%|████████▏ | 337131/414113 [01:18<00:17, 4334.24it/s]\u001b[A\n",
      " 82%|████████▏ | 337565/414113 [01:18<00:17, 4296.34it/s]\u001b[A\n",
      " 82%|████████▏ | 337995/414113 [01:18<00:18, 4227.89it/s]\u001b[A\n",
      " 82%|████████▏ | 338419/414113 [01:18<00:18, 4190.72it/s]\u001b[A\n",
      " 82%|████████▏ | 338849/414113 [01:18<00:17, 4222.64it/s]\u001b[A\n",
      " 82%|████████▏ | 339282/414113 [01:18<00:17, 4252.46it/s]\u001b[A\n",
      " 82%|████████▏ | 339708/414113 [01:18<00:17, 4229.08it/s]\u001b[A\n",
      " 82%|████████▏ | 340132/414113 [01:19<00:17, 4212.62it/s]\u001b[A\n",
      " 82%|████████▏ | 340575/414113 [01:19<00:17, 4275.05it/s]\u001b[A\n",
      " 82%|████████▏ | 341003/414113 [01:19<00:17, 4264.31it/s]\u001b[A\n",
      " 82%|████████▏ | 341430/414113 [01:19<00:17, 4216.93it/s]\u001b[A\n",
      " 83%|████████▎ | 341860/414113 [01:19<00:17, 4239.79it/s]\u001b[A\n",
      " 83%|████████▎ | 342285/414113 [01:19<00:16, 4233.50it/s]\u001b[A\n",
      " 83%|████████▎ | 342723/414113 [01:19<00:16, 4275.30it/s]\u001b[A\n",
      " 83%|████████▎ | 343162/414113 [01:19<00:16, 4307.98it/s]\u001b[A\n",
      " 83%|████████▎ | 343605/414113 [01:19<00:16, 4343.36it/s]\u001b[A\n",
      " 83%|████████▎ | 344048/414113 [01:19<00:16, 4368.91it/s]\u001b[A\n",
      " 83%|████████▎ | 344486/414113 [01:20<00:15, 4351.85it/s]\u001b[A\n",
      " 83%|████████▎ | 344923/414113 [01:20<00:15, 4353.88it/s]\u001b[A\n",
      " 83%|████████▎ | 345363/414113 [01:20<00:15, 4365.72it/s]\u001b[A\n",
      " 84%|████████▎ | 345810/414113 [01:20<00:15, 4395.76it/s]\u001b[A\n",
      " 84%|████████▎ | 346251/414113 [01:20<00:15, 4399.71it/s]\u001b[A\n",
      " 84%|████████▎ | 346692/414113 [01:20<00:15, 4343.91it/s]\u001b[A\n",
      " 84%|████████▍ | 347127/414113 [01:20<00:15, 4341.83it/s]\u001b[A\n",
      " 84%|████████▍ | 347564/414113 [01:20<00:15, 4349.73it/s]\u001b[A\n",
      " 84%|████████▍ | 348000/414113 [01:20<00:15, 4330.25it/s]\u001b[A\n",
      " 84%|████████▍ | 348434/414113 [01:20<00:15, 4312.98it/s]\u001b[A\n",
      " 84%|████████▍ | 348866/414113 [01:21<00:15, 4311.45it/s]\u001b[A\n",
      " 84%|████████▍ | 349303/414113 [01:21<00:14, 4328.50it/s]\u001b[A\n",
      " 84%|████████▍ | 349739/414113 [01:21<00:14, 4337.24it/s]\u001b[A\n",
      " 85%|████████▍ | 350173/414113 [01:21<00:14, 4327.01it/s]\u001b[A\n",
      " 85%|████████▍ | 350620/414113 [01:21<00:14, 4367.65it/s]\u001b[A\n",
      " 85%|████████▍ | 351057/414113 [01:21<00:14, 4350.49it/s]\u001b[A\n",
      " 85%|████████▍ | 351493/414113 [01:21<00:14, 4336.35it/s]\u001b[A\n",
      " 85%|████████▍ | 351930/414113 [01:21<00:14, 4346.24it/s]\u001b[A\n",
      " 85%|████████▌ | 352372/414113 [01:21<00:14, 4367.34it/s]\u001b[A\n",
      " 85%|████████▌ | 352809/414113 [01:21<00:14, 4362.70it/s]\u001b[A\n",
      " 85%|████████▌ | 353246/414113 [01:22<00:13, 4364.78it/s]\u001b[A\n",
      " 85%|████████▌ | 353689/414113 [01:22<00:13, 4382.25it/s]\u001b[A\n",
      " 86%|████████▌ | 354128/414113 [01:22<00:13, 4376.72it/s]\u001b[A\n",
      " 86%|████████▌ | 354566/414113 [01:22<00:14, 4069.69it/s]\u001b[A\n",
      " 86%|████████▌ | 354999/414113 [01:22<00:14, 4143.66it/s]\u001b[A\n",
      " 86%|████████▌ | 355440/414113 [01:22<00:13, 4217.28it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 355875/414113 [01:22<00:13, 4255.91it/s]\u001b[A\n",
      " 86%|████████▌ | 356325/414113 [01:22<00:13, 4324.47it/s]\u001b[A\n",
      " 86%|████████▌ | 356765/414113 [01:22<00:13, 4344.80it/s]\u001b[A\n",
      " 86%|████████▋ | 357201/414113 [01:22<00:13, 4326.60it/s]\u001b[A\n",
      " 86%|████████▋ | 357644/414113 [01:23<00:12, 4355.03it/s]\u001b[A\n",
      " 86%|████████▋ | 358081/414113 [01:23<00:12, 4328.81it/s]\u001b[A\n",
      " 87%|████████▋ | 358529/414113 [01:23<00:12, 4370.19it/s]\u001b[A\n",
      " 87%|████████▋ | 358969/414113 [01:23<00:12, 4376.77it/s]\u001b[A\n",
      " 87%|████████▋ | 359407/414113 [01:23<00:12, 4360.48it/s]\u001b[A\n",
      " 87%|████████▋ | 359844/414113 [01:23<00:12, 4362.50it/s]\u001b[A\n",
      " 87%|████████▋ | 360292/414113 [01:23<00:12, 4396.26it/s]\u001b[A\n",
      " 87%|████████▋ | 360732/414113 [01:23<00:12, 4392.48it/s]\u001b[A\n",
      " 87%|████████▋ | 361172/414113 [01:23<00:12, 4371.24it/s]\u001b[A\n",
      " 87%|████████▋ | 361610/414113 [01:23<00:12, 4341.93it/s]\u001b[A\n",
      " 87%|████████▋ | 362057/414113 [01:24<00:11, 4378.60it/s]\u001b[A\n",
      " 88%|████████▊ | 362496/414113 [01:24<00:11, 4306.32it/s]\u001b[A\n",
      " 88%|████████▊ | 362931/414113 [01:24<00:11, 4318.63it/s]\u001b[A\n",
      " 88%|████████▊ | 363364/414113 [01:24<00:11, 4288.50it/s]\u001b[A\n",
      " 88%|████████▊ | 363794/414113 [01:24<00:11, 4224.61it/s]\u001b[A\n",
      " 88%|████████▊ | 364217/414113 [01:24<00:11, 4211.74it/s]\u001b[A\n",
      " 88%|████████▊ | 364656/414113 [01:24<00:11, 4262.86it/s]\u001b[A\n",
      " 88%|████████▊ | 365083/414113 [01:24<00:11, 4229.93it/s]\u001b[A\n",
      " 88%|████████▊ | 365522/414113 [01:24<00:11, 4276.21it/s]\u001b[A\n",
      " 88%|████████▊ | 365950/414113 [01:24<00:11, 4255.01it/s]\u001b[A\n",
      " 88%|████████▊ | 366397/414113 [01:25<00:11, 4316.24it/s]\u001b[A\n",
      " 89%|████████▊ | 366834/414113 [01:25<00:10, 4330.53it/s]\u001b[A\n",
      " 89%|████████▊ | 367268/414113 [01:25<00:10, 4322.39it/s]\u001b[A\n",
      " 89%|████████▉ | 367705/414113 [01:25<00:10, 4336.23it/s]\u001b[A\n",
      " 89%|████████▉ | 368139/414113 [01:25<00:10, 4298.50it/s]\u001b[A\n",
      " 89%|████████▉ | 368583/414113 [01:25<00:10, 4339.92it/s]\u001b[A\n",
      " 89%|████████▉ | 369026/414113 [01:25<00:10, 4365.04it/s]\u001b[A\n",
      " 89%|████████▉ | 369465/414113 [01:25<00:10, 4371.88it/s]\u001b[A\n",
      " 89%|████████▉ | 369903/414113 [01:25<00:10, 4358.96it/s]\u001b[A\n",
      " 89%|████████▉ | 370340/414113 [01:25<00:10, 4306.71it/s]\u001b[A\n",
      " 90%|████████▉ | 370771/414113 [01:26<00:10, 4293.58it/s]\u001b[A\n",
      " 90%|████████▉ | 371201/414113 [01:26<00:10, 4279.13it/s]\u001b[A\n",
      " 90%|████████▉ | 371630/414113 [01:26<00:09, 4263.07it/s]\u001b[A\n",
      " 90%|████████▉ | 372057/414113 [01:26<00:10, 4196.25it/s]\u001b[A\n",
      " 90%|████████▉ | 372480/414113 [01:26<00:09, 4206.23it/s]\u001b[A\n",
      " 90%|█████████ | 372909/414113 [01:26<00:09, 4231.02it/s]\u001b[A\n",
      " 90%|█████████ | 373346/414113 [01:26<00:09, 4270.60it/s]\u001b[A\n",
      " 90%|█████████ | 373774/414113 [01:26<00:09, 4272.15it/s]\u001b[A\n",
      " 90%|█████████ | 374203/414113 [01:26<00:09, 4276.64it/s]\u001b[A\n",
      " 90%|█████████ | 374638/414113 [01:27<00:09, 4296.29it/s]\u001b[A\n",
      " 91%|█████████ | 375079/414113 [01:27<00:09, 4327.60it/s]\u001b[A\n",
      " 91%|█████████ | 375512/414113 [01:27<00:08, 4325.66it/s]\u001b[A\n",
      " 91%|█████████ | 375956/414113 [01:27<00:08, 4358.92it/s]\u001b[A\n",
      " 91%|█████████ | 376393/414113 [01:27<00:08, 4346.15it/s]\u001b[A\n",
      " 91%|█████████ | 376828/414113 [01:27<00:08, 4328.00it/s]\u001b[A\n",
      " 91%|█████████ | 377261/414113 [01:27<00:08, 4326.87it/s]\u001b[A\n",
      " 91%|█████████ | 377707/414113 [01:27<00:08, 4365.55it/s]\u001b[A\n",
      " 91%|█████████▏| 378144/414113 [01:27<00:08, 4328.39it/s]\u001b[A\n",
      " 91%|█████████▏| 378577/414113 [01:27<00:08, 4297.58it/s]\u001b[A\n",
      " 92%|█████████▏| 379010/414113 [01:28<00:08, 4304.02it/s]\u001b[A\n",
      " 92%|█████████▏| 379442/414113 [01:28<00:08, 4307.03it/s]\u001b[A\n",
      " 92%|█████████▏| 379875/414113 [01:28<00:07, 4312.41it/s]\u001b[A\n",
      " 92%|█████████▏| 380307/414113 [01:28<00:07, 4271.19it/s]\u001b[A\n",
      " 92%|█████████▏| 380744/414113 [01:28<00:07, 4298.39it/s]\u001b[A\n",
      " 92%|█████████▏| 381176/414113 [01:28<00:07, 4304.34it/s]\u001b[A\n",
      " 92%|█████████▏| 381622/414113 [01:28<00:07, 4348.81it/s]\u001b[A\n",
      " 92%|█████████▏| 382067/414113 [01:28<00:07, 4378.09it/s]\u001b[A\n",
      " 92%|█████████▏| 382505/414113 [01:28<00:07, 4375.53it/s]\u001b[A\n",
      " 92%|█████████▏| 382945/414113 [01:28<00:07, 4381.81it/s]\u001b[A\n",
      " 93%|█████████▎| 383384/414113 [01:29<00:07, 4382.94it/s]\u001b[A\n",
      " 93%|█████████▎| 383823/414113 [01:29<00:06, 4377.10it/s]\u001b[A\n",
      " 93%|█████████▎| 384261/414113 [01:29<00:06, 4328.41it/s]\u001b[A\n",
      " 93%|█████████▎| 384711/414113 [01:29<00:06, 4376.09it/s]\u001b[A\n",
      " 93%|█████████▎| 385149/414113 [01:29<00:06, 4363.65it/s]\u001b[A\n",
      " 93%|█████████▎| 385586/414113 [01:29<00:06, 4299.22it/s]\u001b[A\n",
      " 93%|█████████▎| 386017/414113 [01:29<00:06, 4284.24it/s]\u001b[A\n",
      " 93%|█████████▎| 386446/414113 [01:29<00:06, 4269.98it/s]\u001b[A\n",
      " 93%|█████████▎| 386884/414113 [01:29<00:06, 4301.93it/s]\u001b[A\n",
      " 94%|█████████▎| 387315/414113 [01:29<00:06, 4298.14it/s]\u001b[A\n",
      " 94%|█████████▎| 387746/414113 [01:30<00:06, 4300.95it/s]\u001b[A\n",
      " 94%|█████████▎| 388177/414113 [01:30<00:06, 4260.83it/s]\u001b[A\n",
      " 94%|█████████▍| 388604/414113 [01:30<00:05, 4252.90it/s]\u001b[A\n",
      " 94%|█████████▍| 389035/414113 [01:30<00:05, 4268.21it/s]\u001b[A\n",
      " 94%|█████████▍| 389462/414113 [01:30<00:05, 4257.30it/s]\u001b[A\n",
      " 94%|█████████▍| 389902/414113 [01:30<00:05, 4296.17it/s]\u001b[A\n",
      " 94%|█████████▍| 390332/414113 [01:30<00:05, 4291.33it/s]\u001b[A\n",
      " 94%|█████████▍| 390762/414113 [01:30<00:05, 4269.45it/s]\u001b[A\n",
      " 94%|█████████▍| 391190/414113 [01:30<00:05, 4251.75it/s]\u001b[A\n",
      " 95%|█████████▍| 391630/414113 [01:30<00:05, 4292.55it/s]\u001b[A\n",
      " 95%|█████████▍| 392070/414113 [01:31<00:05, 4323.18it/s]\u001b[A\n",
      " 95%|█████████▍| 392503/414113 [01:31<00:05, 4301.84it/s]\u001b[A\n",
      " 95%|█████████▍| 392945/414113 [01:31<00:04, 4335.74it/s]\u001b[A\n",
      " 95%|█████████▍| 393379/414113 [01:31<00:04, 4259.02it/s]\u001b[A\n",
      " 95%|█████████▌| 393814/414113 [01:31<00:04, 4283.80it/s]\u001b[A\n",
      " 95%|█████████▌| 394243/414113 [01:31<00:04, 4276.10it/s]\u001b[A\n",
      " 95%|█████████▌| 394671/414113 [01:31<00:04, 3987.14it/s]\u001b[A\n",
      " 95%|█████████▌| 395104/414113 [01:31<00:04, 4082.73it/s]\u001b[A\n",
      " 96%|█████████▌| 395536/414113 [01:31<00:04, 4149.49it/s]\u001b[A\n",
      " 96%|█████████▌| 395965/414113 [01:31<00:04, 4189.79it/s]\u001b[A\n",
      " 96%|█████████▌| 396412/414113 [01:32<00:04, 4268.84it/s]\u001b[A\n",
      " 96%|█████████▌| 396852/414113 [01:32<00:04, 4306.67it/s]\u001b[A\n",
      " 96%|█████████▌| 397292/414113 [01:32<00:03, 4330.97it/s]\u001b[A\n",
      " 96%|█████████▌| 397727/414113 [01:32<00:03, 4309.63it/s]\u001b[A\n",
      " 96%|█████████▌| 398159/414113 [01:32<00:03, 4301.07it/s]\u001b[A\n",
      " 96%|█████████▋| 398600/414113 [01:32<00:03, 4333.10it/s]\u001b[A\n",
      " 96%|█████████▋| 399034/414113 [01:32<00:03, 4290.86it/s]\u001b[A\n",
      " 96%|█████████▋| 399471/414113 [01:32<00:03, 4312.27it/s]\u001b[A\n",
      " 97%|█████████▋| 399903/414113 [01:32<00:03, 4313.20it/s]\u001b[A\n",
      " 97%|█████████▋| 400335/414113 [01:32<00:03, 4294.21it/s]\u001b[A\n",
      " 97%|█████████▋| 400771/414113 [01:33<00:03, 4312.77it/s]\u001b[A\n",
      " 97%|█████████▋| 401203/414113 [01:33<00:03, 4299.39it/s]\u001b[A\n",
      " 97%|█████████▋| 401645/414113 [01:33<00:02, 4332.81it/s]\u001b[A\n",
      " 97%|█████████▋| 402079/414113 [01:33<00:02, 4302.66it/s]\u001b[A\n",
      " 97%|█████████▋| 402511/414113 [01:33<00:02, 4306.36it/s]\u001b[A\n",
      " 97%|█████████▋| 402951/414113 [01:33<00:02, 4333.32it/s]\u001b[A\n",
      " 97%|█████████▋| 403389/414113 [01:33<00:02, 4345.42it/s]\u001b[A\n",
      " 98%|█████████▊| 403831/414113 [01:33<00:02, 4364.97it/s]\u001b[A\n",
      " 98%|█████████▊| 404281/414113 [01:33<00:02, 4403.28it/s]\u001b[A\n",
      " 98%|█████████▊| 404722/414113 [01:33<00:02, 4398.99it/s]\u001b[A\n",
      " 98%|█████████▊| 405162/414113 [01:34<00:02, 4384.88it/s]\u001b[A\n",
      " 98%|█████████▊| 405604/414113 [01:34<00:01, 4394.19it/s]\u001b[A\n",
      " 98%|█████████▊| 406044/414113 [01:34<00:01, 4375.28it/s]\u001b[A\n",
      " 98%|█████████▊| 406482/414113 [01:34<00:01, 4352.19it/s]\u001b[A\n",
      " 98%|█████████▊| 406921/414113 [01:34<00:01, 4359.84it/s]\u001b[A\n",
      " 98%|█████████▊| 407362/414113 [01:34<00:01, 4372.79it/s]\u001b[A\n",
      " 98%|█████████▊| 407800/414113 [01:34<00:01, 4370.78it/s]\u001b[A\n",
      " 99%|█████████▊| 408238/414113 [01:34<00:01, 4321.58it/s]\u001b[A\n",
      " 99%|█████████▊| 408685/414113 [01:34<00:01, 4362.30it/s]\u001b[A\n",
      " 99%|█████████▉| 409126/414113 [01:34<00:01, 4374.54it/s]\u001b[A\n",
      " 99%|█████████▉| 409564/414113 [01:35<00:01, 4358.65it/s]\u001b[A\n",
      " 99%|█████████▉| 410005/414113 [01:35<00:00, 4371.42it/s]\u001b[A\n",
      " 99%|█████████▉| 410453/414113 [01:35<00:00, 4402.00it/s]\u001b[A\n",
      " 99%|█████████▉| 410894/414113 [01:35<00:00, 4334.75it/s]\u001b[A\n",
      " 99%|█████████▉| 411328/414113 [01:35<00:00, 4323.03it/s]\u001b[A\n",
      " 99%|█████████▉| 411761/414113 [01:35<00:00, 4290.23it/s]\u001b[A\n",
      "100%|█████████▉| 412197/414113 [01:35<00:00, 4309.42it/s]\u001b[A\n",
      "100%|█████████▉| 412645/414113 [01:35<00:00, 4357.45it/s]\u001b[A\n",
      "100%|█████████▉| 413095/414113 [01:35<00:00, 4397.12it/s]\u001b[A\n",
      "100%|█████████▉| 413541/414113 [01:36<00:00, 4414.04it/s]\u001b[A\n",
      "100%|█████████▉| 413983/414113 [01:36<00:00, 4385.49it/s]\u001b[A\n",
      "100%|██████████| 414113/414113 [01:36<00:00, 4307.32it/s]\u001b[ADownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
      "\n",
      "  0%|          | 0/102502400 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 2727936/102502400 [00:00<00:03, 27272688.62it/s]\u001b[A\n",
      "  4%|▍         | 4194304/102502400 [00:00<00:04, 20134321.28it/s]\u001b[A\n",
      "  6%|▌         | 5898240/102502400 [00:00<00:05, 18907653.57it/s]\u001b[A\n",
      "  7%|▋         | 7274496/102502400 [00:00<00:05, 16821246.88it/s]\u001b[A\n",
      " 10%|▉         | 9895936/102502400 [00:00<00:04, 18816380.28it/s]\u001b[A\n",
      " 12%|█▏        | 11952128/102502400 [00:00<00:04, 19282589.52it/s]\u001b[A\n",
      " 13%|█▎        | 13713408/102502400 [00:00<00:05, 17601948.82it/s]\u001b[A\n",
      " 15%|█▌        | 15384576/102502400 [00:00<00:05, 17178026.88it/s]\u001b[A\n",
      " 17%|█▋        | 17047552/102502400 [00:00<00:05, 15125896.18it/s]\u001b[A\n",
      " 18%|█▊        | 18579456/102502400 [00:01<00:05, 15181866.58it/s]\u001b[A\n",
      " 20%|█▉        | 20103168/102502400 [00:01<00:06, 13324710.75it/s]\u001b[A\n",
      " 22%|██▏       | 22085632/102502400 [00:01<00:05, 14425617.44it/s]\u001b[A\n",
      " 23%|██▎       | 23584768/102502400 [00:01<00:06, 12258499.87it/s]\u001b[A\n",
      " 25%|██▌       | 26083328/102502400 [00:01<00:05, 14425826.86it/s]\u001b[A\n",
      " 27%|██▋       | 27746304/102502400 [00:01<00:05, 14789321.94it/s]\u001b[A\n",
      " 29%|██▉       | 29622272/102502400 [00:01<00:04, 15782950.21it/s]\u001b[A\n",
      " 31%|███       | 31334400/102502400 [00:01<00:04, 14367115.50it/s]\u001b[A\n",
      " 32%|███▏      | 32890880/102502400 [00:02<00:06, 11395245.60it/s]\u001b[A\n",
      " 33%|███▎      | 34209792/102502400 [00:02<00:05, 11769049.16it/s]\u001b[A\n",
      " 35%|███▍      | 35717120/102502400 [00:02<00:05, 12122384.33it/s]\u001b[A\n",
      " 36%|███▌      | 37027840/102502400 [00:02<00:05, 11149644.04it/s]\u001b[A\n",
      " 38%|███▊      | 38666240/102502400 [00:02<00:05, 12310819.95it/s]\u001b[A\n",
      " 40%|████      | 41418752/102502400 [00:02<00:04, 14747887.96it/s]\u001b[A\n",
      " 42%|████▏     | 43319296/102502400 [00:02<00:03, 15599055.51it/s]\u001b[A\n",
      " 44%|████▍     | 45088768/102502400 [00:03<00:05, 10765228.09it/s]\u001b[A\n",
      " 46%|████▋     | 47505408/102502400 [00:03<00:04, 12912915.48it/s]\u001b[A\n",
      " 49%|████▉     | 50331648/102502400 [00:03<00:03, 15385584.67it/s]\u001b[A\n",
      " 51%|█████     | 52371456/102502400 [00:03<00:04, 12046078.79it/s]\u001b[A\n",
      " 53%|█████▎    | 54042624/102502400 [00:03<00:04, 10827327.00it/s]\u001b[A\n",
      " 54%|█████▍    | 55705600/102502400 [00:03<00:03, 11929963.50it/s]\u001b[A\n",
      " 56%|█████▋    | 57802752/102502400 [00:03<00:03, 13693405.56it/s]\u001b[A\n",
      " 59%|█████▉    | 60489728/102502400 [00:04<00:02, 16049876.41it/s]\u001b[A\n",
      " 61%|██████    | 62455808/102502400 [00:04<00:02, 14608641.57it/s]\u001b[A\n",
      " 63%|██████▎   | 65077248/102502400 [00:04<00:02, 16563148.83it/s]\u001b[A\n",
      " 65%|██████▌   | 67018752/102502400 [00:04<00:03, 11721088.61it/s]\u001b[A\n",
      " 67%|██████▋   | 68591616/102502400 [00:04<00:03, 10670872.17it/s]\u001b[A\n",
      " 69%|██████▉   | 70909952/102502400 [00:04<00:02, 12481351.12it/s]\u001b[A\n",
      " 71%|███████   | 72482816/102502400 [00:05<00:03, 9517389.37it/s] \u001b[A\n",
      " 72%|███████▏  | 73768960/102502400 [00:05<00:02, 10235129.57it/s]\u001b[A\n",
      " 73%|███████▎  | 75046912/102502400 [00:05<00:02, 10832498.65it/s]\u001b[A\n",
      " 75%|███████▍  | 76546048/102502400 [00:05<00:02, 11685372.16it/s]\u001b[A\n",
      " 76%|███████▋  | 78381056/102502400 [00:05<00:01, 12639053.40it/s]\u001b[A\n",
      " 78%|███████▊  | 80150528/102502400 [00:05<00:01, 13760562.37it/s]\u001b[A\n",
      " 80%|███████▉  | 81649664/102502400 [00:05<00:01, 13988870.03it/s]\u001b[A\n",
      " 81%|████████  | 83132416/102502400 [00:05<00:01, 13792890.20it/s]\u001b[A\n",
      " 83%|████████▎ | 84574208/102502400 [00:06<00:01, 13027174.88it/s]\u001b[A\n",
      " 84%|████████▍ | 85934080/102502400 [00:06<00:01, 9171558.71it/s] \u001b[A\n",
      " 85%|████████▍ | 87048192/102502400 [00:06<00:01, 9588865.90it/s]\u001b[A\n",
      " 86%|████████▌ | 88154112/102502400 [00:06<00:01, 9369321.45it/s]\u001b[A\n",
      " 87%|████████▋ | 89194496/102502400 [00:06<00:01, 8597291.04it/s]\u001b[A\n",
      " 88%|████████▊ | 90136576/102502400 [00:06<00:01, 7694650.71it/s]\u001b[A\n",
      " 89%|████████▉ | 91619328/102502400 [00:06<00:01, 8891380.35it/s]\u001b[A\n",
      " 90%|█████████ | 92733440/102502400 [00:07<00:01, 9445271.99it/s]\u001b[A\n",
      " 92%|█████████▏| 94633984/102502400 [00:07<00:00, 11024215.01it/s]\u001b[A\n",
      " 95%|█████████▍| 96944128/102502400 [00:07<00:00, 13074479.39it/s]\u001b[A\n",
      " 96%|█████████▌| 98533376/102502400 [00:07<00:00, 13552168.00it/s]\u001b[A\n",
      " 98%|█████████▊| 100663296/102502400 [00:07<00:00, 13924994.24it/s]\u001b[A\n",
      "100%|█████████▉| 102203392/102502400 [00:07<00:00, 13766640.99it/s]\u001b[A\n",
      "100%|██████████| 102502400/102502400 [00:07<00:00, 13487761.86it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 64          # batch size\n",
    "vocab_threshold = 3        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 512           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(params, lr=lr)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/6471], Loss: 3.7239, Perplexity: 41.42451\n",
      "Epoch [1/3], Step [200/6471], Loss: 3.4215, Perplexity: 30.6139\n",
      "Epoch [1/3], Step [300/6471], Loss: 3.2297, Perplexity: 25.27209\n",
      "Epoch [1/3], Step [400/6471], Loss: 3.1816, Perplexity: 24.0858\n",
      "Epoch [1/3], Step [500/6471], Loss: 2.9894, Perplexity: 19.8729\n",
      "Epoch [1/3], Step [600/6471], Loss: 2.7779, Perplexity: 16.08530\n",
      "Epoch [1/3], Step [700/6471], Loss: 3.0749, Perplexity: 21.6479\n",
      "Epoch [1/3], Step [800/6471], Loss: 2.9168, Perplexity: 18.4827\n",
      "Epoch [1/3], Step [900/6471], Loss: 2.7733, Perplexity: 16.0117\n",
      "Epoch [1/3], Step [1000/6471], Loss: 2.5921, Perplexity: 13.3581\n",
      "Epoch [1/3], Step [1100/6471], Loss: 2.6660, Perplexity: 14.3830\n",
      "Epoch [1/3], Step [1200/6471], Loss: 2.6439, Perplexity: 14.0685\n",
      "Epoch [1/3], Step [1300/6471], Loss: 2.7233, Perplexity: 15.2304\n",
      "Epoch [1/3], Step [1400/6471], Loss: 2.5365, Perplexity: 12.6355\n",
      "Epoch [1/3], Step [1500/6471], Loss: 2.4594, Perplexity: 11.6973\n",
      "Epoch [1/3], Step [1600/6471], Loss: 2.8376, Perplexity: 17.0747\n",
      "Epoch [1/3], Step [1700/6471], Loss: 2.5733, Perplexity: 13.10964\n",
      "Epoch [1/3], Step [1800/6471], Loss: 2.4429, Perplexity: 11.5068\n",
      "Epoch [1/3], Step [1900/6471], Loss: 2.2931, Perplexity: 9.90550\n",
      "Epoch [1/3], Step [2000/6471], Loss: 3.2898, Perplexity: 26.8378\n",
      "Epoch [1/3], Step [2100/6471], Loss: 2.4752, Perplexity: 11.8846\n",
      "Epoch [1/3], Step [2200/6471], Loss: 2.1923, Perplexity: 8.95549\n",
      "Epoch [1/3], Step [2300/6471], Loss: 2.8408, Perplexity: 17.13037\n",
      "Epoch [1/3], Step [2400/6471], Loss: 2.3026, Perplexity: 10.0001\n",
      "Epoch [1/3], Step [2500/6471], Loss: 2.4655, Perplexity: 11.7698\n",
      "Epoch [1/3], Step [2600/6471], Loss: 2.2912, Perplexity: 9.88635\n",
      "Epoch [1/3], Step [2700/6471], Loss: 2.1648, Perplexity: 8.71314\n",
      "Epoch [1/3], Step [2800/6471], Loss: 2.3501, Perplexity: 10.4862\n",
      "Epoch [1/3], Step [2900/6471], Loss: 2.3901, Perplexity: 10.9149\n",
      "Epoch [1/3], Step [3000/6471], Loss: 2.2866, Perplexity: 9.84189\n",
      "Epoch [1/3], Step [3100/6471], Loss: 2.3499, Perplexity: 10.4848\n",
      "Epoch [1/3], Step [3200/6471], Loss: 2.1685, Perplexity: 8.74540\n",
      "Epoch [1/3], Step [3300/6471], Loss: 2.1686, Perplexity: 8.74625\n",
      "Epoch [1/3], Step [3400/6471], Loss: 2.1963, Perplexity: 8.99138\n",
      "Epoch [1/3], Step [3500/6471], Loss: 2.2194, Perplexity: 9.20162\n",
      "Epoch [1/3], Step [3600/6471], Loss: 2.3008, Perplexity: 9.98235\n",
      "Epoch [1/3], Step [3700/6471], Loss: 2.2323, Perplexity: 9.32166\n",
      "Epoch [1/3], Step [3800/6471], Loss: 2.1156, Perplexity: 8.29454\n",
      "Epoch [1/3], Step [3900/6471], Loss: 2.6211, Perplexity: 13.7514\n",
      "Epoch [1/3], Step [4000/6471], Loss: 2.1937, Perplexity: 8.96813\n",
      "Epoch [1/3], Step [4100/6471], Loss: 2.3768, Perplexity: 10.7709\n",
      "Epoch [1/3], Step [4200/6471], Loss: 2.2510, Perplexity: 9.49694\n",
      "Epoch [1/3], Step [4300/6471], Loss: 2.3653, Perplexity: 10.6468\n",
      "Epoch [1/3], Step [4400/6471], Loss: 2.2743, Perplexity: 9.72118\n",
      "Epoch [1/3], Step [4500/6471], Loss: 2.8193, Perplexity: 16.7657\n",
      "Epoch [1/3], Step [4600/6471], Loss: 2.4177, Perplexity: 11.2204\n",
      "Epoch [1/3], Step [4700/6471], Loss: 2.2245, Perplexity: 9.24897\n",
      "Epoch [1/3], Step [4800/6471], Loss: 2.3923, Perplexity: 10.9383\n",
      "Epoch [1/3], Step [4900/6471], Loss: 2.0994, Perplexity: 8.16164\n",
      "Epoch [1/3], Step [5000/6471], Loss: 2.0941, Perplexity: 8.11843\n",
      "Epoch [1/3], Step [5100/6471], Loss: 2.2906, Perplexity: 9.88062\n",
      "Epoch [1/3], Step [5200/6471], Loss: 2.6421, Perplexity: 14.0431\n",
      "Epoch [1/3], Step [5300/6471], Loss: 2.3995, Perplexity: 11.0177\n",
      "Epoch [1/3], Step [5400/6471], Loss: 2.1590, Perplexity: 8.66242\n",
      "Epoch [1/3], Step [5500/6471], Loss: 2.1903, Perplexity: 8.93801\n",
      "Epoch [1/3], Step [5600/6471], Loss: 2.1456, Perplexity: 8.54720\n",
      "Epoch [1/3], Step [5700/6471], Loss: 2.2334, Perplexity: 9.33176\n",
      "Epoch [1/3], Step [5800/6471], Loss: 2.2552, Perplexity: 9.53718\n",
      "Epoch [1/3], Step [5900/6471], Loss: 2.0658, Perplexity: 7.89166\n",
      "Epoch [1/3], Step [6000/6471], Loss: 2.0502, Perplexity: 7.76951\n",
      "Epoch [1/3], Step [6100/6471], Loss: 2.3534, Perplexity: 10.5217\n",
      "Epoch [1/3], Step [6200/6471], Loss: 2.2680, Perplexity: 9.66054\n",
      "Epoch [1/3], Step [6300/6471], Loss: 2.2507, Perplexity: 9.49401\n",
      "Epoch [1/3], Step [6400/6471], Loss: 2.5133, Perplexity: 12.3455\n",
      "Epoch [2/3], Step [100/6471], Loss: 2.3067, Perplexity: 10.04103\n",
      "Epoch [2/3], Step [200/6471], Loss: 2.7559, Perplexity: 15.7358\n",
      "Epoch [2/3], Step [300/6471], Loss: 2.5829, Perplexity: 13.2348\n",
      "Epoch [2/3], Step [400/6471], Loss: 1.9543, Perplexity: 7.05898\n",
      "Epoch [2/3], Step [500/6471], Loss: 1.9987, Perplexity: 7.37957\n",
      "Epoch [2/3], Step [600/6471], Loss: 2.4317, Perplexity: 11.3778\n",
      "Epoch [2/3], Step [700/6471], Loss: 2.0975, Perplexity: 8.14541\n",
      "Epoch [2/3], Step [800/6471], Loss: 2.1453, Perplexity: 8.54474\n",
      "Epoch [2/3], Step [900/6471], Loss: 2.0212, Perplexity: 7.54710\n",
      "Epoch [2/3], Step [1000/6471], Loss: 1.9798, Perplexity: 7.2415\n",
      "Epoch [2/3], Step [1100/6471], Loss: 2.2150, Perplexity: 9.16154\n",
      "Epoch [2/3], Step [1200/6471], Loss: 2.0366, Perplexity: 7.66427\n",
      "Epoch [2/3], Step [1300/6471], Loss: 2.1371, Perplexity: 8.47483\n",
      "Epoch [2/3], Step [1400/6471], Loss: 1.8672, Perplexity: 6.47009\n",
      "Epoch [2/3], Step [1500/6471], Loss: 2.0507, Perplexity: 7.77313\n",
      "Epoch [2/3], Step [1600/6471], Loss: 2.0360, Perplexity: 7.66000\n",
      "Epoch [2/3], Step [1700/6471], Loss: 2.8601, Perplexity: 17.4634\n",
      "Epoch [2/3], Step [1800/6471], Loss: 2.4502, Perplexity: 11.5911\n",
      "Epoch [2/3], Step [1900/6471], Loss: 2.0644, Perplexity: 7.88043\n",
      "Epoch [2/3], Step [2000/6471], Loss: 1.9517, Perplexity: 7.04087\n",
      "Epoch [2/3], Step [2100/6471], Loss: 2.0874, Perplexity: 8.06405\n",
      "Epoch [2/3], Step [2200/6471], Loss: 1.9675, Perplexity: 7.152522\n",
      "Epoch [2/3], Step [2300/6471], Loss: 2.1245, Perplexity: 8.36836\n",
      "Epoch [2/3], Step [2400/6471], Loss: 1.9805, Perplexity: 7.24646\n",
      "Epoch [2/3], Step [2500/6471], Loss: 2.1580, Perplexity: 8.65407\n",
      "Epoch [2/3], Step [2600/6471], Loss: 2.1235, Perplexity: 8.36062\n",
      "Epoch [2/3], Step [2700/6471], Loss: 2.2578, Perplexity: 9.56173\n",
      "Epoch [2/3], Step [2800/6471], Loss: 2.1080, Perplexity: 8.23197\n",
      "Epoch [2/3], Step [2900/6471], Loss: 1.8569, Perplexity: 6.40365\n",
      "Epoch [2/3], Step [3000/6471], Loss: 2.0193, Perplexity: 7.53279\n",
      "Epoch [2/3], Step [3100/6471], Loss: 2.1521, Perplexity: 8.60258\n",
      "Epoch [2/3], Step [3200/6471], Loss: 2.1967, Perplexity: 8.99560\n",
      "Epoch [2/3], Step [3300/6471], Loss: 2.0468, Perplexity: 7.74329\n",
      "Epoch [2/3], Step [3400/6471], Loss: 2.2291, Perplexity: 9.29166\n",
      "Epoch [2/3], Step [3500/6471], Loss: 1.9896, Perplexity: 7.31253\n",
      "Epoch [2/3], Step [3600/6471], Loss: 2.2646, Perplexity: 9.62765\n",
      "Epoch [2/3], Step [3700/6471], Loss: 2.0173, Perplexity: 7.51779\n",
      "Epoch [2/3], Step [3800/6471], Loss: 2.2279, Perplexity: 9.28080\n",
      "Epoch [2/3], Step [3900/6471], Loss: 1.9423, Perplexity: 6.97452\n",
      "Epoch [2/3], Step [4000/6471], Loss: 1.8163, Perplexity: 6.14920\n",
      "Epoch [2/3], Step [4100/6471], Loss: 2.5358, Perplexity: 12.6265\n",
      "Epoch [2/3], Step [4200/6471], Loss: 2.5668, Perplexity: 13.0237\n",
      "Epoch [2/3], Step [4300/6471], Loss: 2.2498, Perplexity: 9.48551\n",
      "Epoch [2/3], Step [4400/6471], Loss: 2.1882, Perplexity: 8.91941\n",
      "Epoch [2/3], Step [4500/6471], Loss: 1.9765, Perplexity: 7.21753\n",
      "Epoch [2/3], Step [4600/6471], Loss: 2.2266, Perplexity: 9.26825\n",
      "Epoch [2/3], Step [4700/6471], Loss: 2.0072, Perplexity: 7.44251\n",
      "Epoch [2/3], Step [4800/6471], Loss: 1.8704, Perplexity: 6.49072\n",
      "Epoch [2/3], Step [4900/6471], Loss: 1.9966, Perplexity: 7.36414\n",
      "Epoch [2/3], Step [5000/6471], Loss: 2.6162, Perplexity: 13.6837\n",
      "Epoch [2/3], Step [5100/6471], Loss: 1.9346, Perplexity: 6.92136\n",
      "Epoch [2/3], Step [5200/6471], Loss: 1.9865, Perplexity: 7.29007\n",
      "Epoch [2/3], Step [5300/6471], Loss: 2.1318, Perplexity: 8.43039\n",
      "Epoch [2/3], Step [5400/6471], Loss: 1.8745, Perplexity: 6.51758\n",
      "Epoch [2/3], Step [5500/6471], Loss: 1.9243, Perplexity: 6.85026\n",
      "Epoch [2/3], Step [5600/6471], Loss: 1.9963, Perplexity: 7.36196\n",
      "Epoch [2/3], Step [5700/6471], Loss: 1.9654, Perplexity: 7.13789\n",
      "Epoch [2/3], Step [5800/6471], Loss: 1.9276, Perplexity: 6.87287\n",
      "Epoch [2/3], Step [5900/6471], Loss: 1.9853, Perplexity: 7.28134\n",
      "Epoch [2/3], Step [6000/6471], Loss: 2.0299, Perplexity: 7.61357\n",
      "Epoch [2/3], Step [6100/6471], Loss: 2.2901, Perplexity: 9.87631\n",
      "Epoch [2/3], Step [6200/6471], Loss: 1.9269, Perplexity: 6.86840\n",
      "Epoch [2/3], Step [6300/6471], Loss: 1.8922, Perplexity: 6.63404\n",
      "Epoch [2/3], Step [6400/6471], Loss: 1.9453, Perplexity: 6.99558\n",
      "Epoch [3/3], Step [100/6471], Loss: 1.9479, Perplexity: 7.013869\n",
      "Epoch [3/3], Step [200/6471], Loss: 1.9459, Perplexity: 6.99985\n",
      "Epoch [3/3], Step [300/6471], Loss: 2.0514, Perplexity: 7.77914\n",
      "Epoch [3/3], Step [400/6471], Loss: 1.8560, Perplexity: 6.39839\n",
      "Epoch [3/3], Step [500/6471], Loss: 1.9610, Perplexity: 7.10666\n",
      "Epoch [3/3], Step [600/6471], Loss: 2.0143, Perplexity: 7.49512\n",
      "Epoch [3/3], Step [700/6471], Loss: 1.9198, Perplexity: 6.81946\n",
      "Epoch [3/3], Step [800/6471], Loss: 2.4141, Perplexity: 11.1793\n",
      "Epoch [3/3], Step [900/6471], Loss: 1.9150, Perplexity: 6.78726\n",
      "Epoch [3/3], Step [1000/6471], Loss: 1.9252, Perplexity: 6.8564\n",
      "Epoch [3/3], Step [1100/6471], Loss: 2.1629, Perplexity: 8.69672\n",
      "Epoch [3/3], Step [1200/6471], Loss: 2.0780, Perplexity: 7.98878\n",
      "Epoch [3/3], Step [1300/6471], Loss: 2.1665, Perplexity: 8.72777\n",
      "Epoch [3/3], Step [1400/6471], Loss: 2.7158, Perplexity: 15.1163\n",
      "Epoch [3/3], Step [1500/6471], Loss: 2.2169, Perplexity: 9.17896\n",
      "Epoch [3/3], Step [1600/6471], Loss: 1.9406, Perplexity: 6.96285\n",
      "Epoch [3/3], Step [1700/6471], Loss: 1.9409, Perplexity: 6.96520\n",
      "Epoch [3/3], Step [1800/6471], Loss: 2.0023, Perplexity: 7.40619\n",
      "Epoch [3/3], Step [1900/6471], Loss: 2.0096, Perplexity: 7.46032\n",
      "Epoch [3/3], Step [2000/6471], Loss: 1.7322, Perplexity: 5.65335\n",
      "Epoch [3/3], Step [2100/6471], Loss: 2.1162, Perplexity: 8.29949\n",
      "Epoch [3/3], Step [2200/6471], Loss: 2.3393, Perplexity: 10.3735\n",
      "Epoch [3/3], Step [2300/6471], Loss: 1.9917, Perplexity: 7.32836\n",
      "Epoch [3/3], Step [2400/6471], Loss: 2.2148, Perplexity: 9.15982\n",
      "Epoch [3/3], Step [2500/6471], Loss: 2.0734, Perplexity: 7.95155\n",
      "Epoch [3/3], Step [2600/6471], Loss: 1.8315, Perplexity: 6.24353\n",
      "Epoch [3/3], Step [2700/6471], Loss: 1.9088, Perplexity: 6.74538\n",
      "Epoch [3/3], Step [2800/6471], Loss: 1.9208, Perplexity: 6.82666\n",
      "Epoch [3/3], Step [2900/6471], Loss: 1.8886, Perplexity: 6.60981\n",
      "Epoch [3/3], Step [3000/6471], Loss: 1.8615, Perplexity: 6.43327\n",
      "Epoch [3/3], Step [3100/6471], Loss: 1.8075, Perplexity: 6.09517\n",
      "Epoch [3/3], Step [3200/6471], Loss: 1.9465, Perplexity: 7.00432\n",
      "Epoch [3/3], Step [3300/6471], Loss: 2.0286, Perplexity: 7.60334\n",
      "Epoch [3/3], Step [3400/6471], Loss: 2.0349, Perplexity: 7.65147\n",
      "Epoch [3/3], Step [3500/6471], Loss: 1.9000, Perplexity: 6.68564\n",
      "Epoch [3/3], Step [3600/6471], Loss: 1.9864, Perplexity: 7.28907\n",
      "Epoch [3/3], Step [3700/6471], Loss: 1.8580, Perplexity: 6.41114\n",
      "Epoch [3/3], Step [3800/6471], Loss: 2.0497, Perplexity: 7.76578\n",
      "Epoch [3/3], Step [3900/6471], Loss: 1.8531, Perplexity: 6.37975\n",
      "Epoch [3/3], Step [4000/6471], Loss: 1.8770, Perplexity: 6.53426\n",
      "Epoch [3/3], Step [4100/6471], Loss: 2.0478, Perplexity: 7.75123\n",
      "Epoch [3/3], Step [4200/6471], Loss: 1.9979, Perplexity: 7.37323\n",
      "Epoch [3/3], Step [4300/6471], Loss: 1.9681, Perplexity: 7.15726\n",
      "Epoch [3/3], Step [4400/6471], Loss: 1.7687, Perplexity: 5.86344\n",
      "Epoch [3/3], Step [4500/6471], Loss: 1.7715, Perplexity: 5.87944\n",
      "Epoch [3/3], Step [4600/6471], Loss: 1.9566, Perplexity: 7.07517\n",
      "Epoch [3/3], Step [4700/6471], Loss: 2.0613, Perplexity: 7.85610\n",
      "Epoch [3/3], Step [4800/6471], Loss: 1.9540, Perplexity: 7.05670\n",
      "Epoch [3/3], Step [4900/6471], Loss: 1.9671, Perplexity: 7.15012\n",
      "Epoch [3/3], Step [5000/6471], Loss: 1.9573, Perplexity: 7.08034\n",
      "Epoch [3/3], Step [5100/6471], Loss: 2.0690, Perplexity: 7.91657\n",
      "Epoch [3/3], Step [5200/6471], Loss: 2.0719, Perplexity: 7.93951\n",
      "Epoch [3/3], Step [5300/6471], Loss: 1.8482, Perplexity: 6.34838\n",
      "Epoch [3/3], Step [5400/6471], Loss: 1.8767, Perplexity: 6.53168\n",
      "Epoch [3/3], Step [5500/6471], Loss: 1.9986, Perplexity: 7.37848\n",
      "Epoch [3/3], Step [5600/6471], Loss: 1.9803, Perplexity: 7.24460\n",
      "Epoch [3/3], Step [5700/6471], Loss: 2.0456, Perplexity: 7.73371\n",
      "Epoch [3/3], Step [5800/6471], Loss: 1.8224, Perplexity: 6.18686\n",
      "Epoch [3/3], Step [5900/6471], Loss: 1.7679, Perplexity: 5.85879\n",
      "Epoch [3/3], Step [6000/6471], Loss: 1.9070, Perplexity: 6.73287\n",
      "Epoch [3/3], Step [6100/6471], Loss: 1.9914, Perplexity: 7.32552\n",
      "Epoch [3/3], Step [6200/6471], Loss: 1.9218, Perplexity: 6.83316\n",
      "Epoch [3/3], Step [6300/6471], Loss: 2.0693, Perplexity: 7.91941\n",
      "Epoch [3/3], Step [6400/6471], Loss: 1.8618, Perplexity: 6.43510\n",
      "Epoch [3/3], Step [6471/6471], Loss: 1.7301, Perplexity: 5.64094"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
