# computer_vision_nanodegree
Projects from Udacity Computer Vision Nanodegree

## 1. Facial Keypoint Detection

### Project Overview
In this project, it will combine knowledge of computer vision techniques and deep learning architectures to build a facial keypoint detection system. 
Facial keypoints include points around the eyes, nose, and mouth on a face and are used in many applications. 
These applications include: facial tracking, facial pose recognition, facial filters, and emotion recognition. 
The completed code should be able to look at any image, detect faces, and predict the locations of facial keypoints on each face.

### Project Instructions
The project will be broken up into a few main parts in four Python notebooks:
Notebook 1 : Loading and Visualizing the Facial Keypoint Data
Notebook 2 : Defining and Training a Convolutional Neural Network (CNN) to Predict Facial Keypoints
Notebook 3 : Facial Keypoint Detection Using Haar Cascades and your Trained CNN
Notebook 4 : Fun Filters and Keypoint Uses

## 2. Image Captioning

### Project Overview
In this project, it will created a neural network architecture to automatically generate captions from images.
Dataset: Microsoft Common Objects in COntext (MS COCO)

### Project Instructions
The project is structured as a series of Jupyter notebooks that are designed to be completed in sequential order:
0_Dataset.ipynb
1_Preliminaries.ipynb
2_Training.ipynb
3_Inference.ipynb

## 3. Landmark Detection & Robot Tracking (SLAM)

### Project Overview
In this project, it will be implement SLAM (Simultaneous Localization and Mapping) for a 2 dimensional world. 
It will combine knowledge about robot sensor measurements and movement to create a map of an environment from only sensor and motion data gathered by a robot, over time. 
SLAM gives a way to track the location of a robot in the world in real-time and identify the locations of landmarks such as buildings, trees, rocks, and other world features. This is an active area of research in the fields of robotics and autonomous systems.

### Project Instructions
The project will be broken up into three Python notebooks; the first two are for exploration of provided code and a review of SLAM architectures.
Notebook 1 : Robot Moving and Sensing
Notebook 2 : Omega and Xi, Constraints
Notebook 3 : Landmark Detection and Tracking
